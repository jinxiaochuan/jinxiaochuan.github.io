[{"id":"495c7f3561d14b86e5bb70506dad2bf9","title":"NodeJS Stream","content":"\n\n\n\n\n\n\n\n\nStreams are Node’s best and most misunderstood idea. – Dominic Tarr\nStream 是什么？\n\n\n\n\n\n\n\n\nStreams are collections of data – just like arrays or strings. The difference is that streams might not be available all at once and they don’t have to fit in memory. This makes streams really powerful when working with large amounts of data, or data that’s coming from an external source one chunk at a time.流是数据的集合，就像数组或字符串一样。不同之处在于，流可能不会一次全部可用，而且它们不必放入内存中。这使得流在处理大量数据或来自外部源的数据时非常强大，每次处理一个数据块。\nMany of the built-in modules in Node implement the streaming interface:\n\n\n\nReadable Streams\nWritable Streams\n\n\n\nHTTP response, on the client\nHTTP requests, on the client\n\n\nHTTP requests, on the server\nHTTP responses, on the server\n\n\nfs read streams\nfs write streams\n\n\nzlib streams\nzlib streams\n\n\ncrypto streams\ncrypto streams\n\n\nTCP sockets\nTCP sockets\n\n\nchild process stdout &amp; stderr\nchild process stdout\n\n\nprocess.stdin\nprocess.stdout, process.stderr\n\n\n注意 ⚠️：\n\nHTTP response 在客户端虽然是可读流，但是在服务端是可写流。这是因为在 HTTP 情况下，我们基本上是从一个对象(HTTP.IncomingMessage)读取数据，然后写入另一个对象(HTTP.ServerResponse) 。\n有些既是可读流又是可写流，比如 TCP sockets 、 zlib streams 、 crypto streams 。\n\n从大文件请求窥探 Stream 优势\n\n\n\n\n\n\n\n\n创建一个大约 400 MB 的大文件\nconst fs = require(\"fs\");\nconst file = fs.createWriteStream(\"./big.file\");\n\nfor (let i = 0; i &lt;= 1e6; i++) &#123;\n file.write(\n   \"Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n\"\n );\n&#125;\n\nfile.end();\n\n起个简单的服务以访问大文件\nconst fs = require(\"fs\");\nconst server = require(\"http\").createServer();\n\nserver.on(\"request\", (req, res) => &#123;\n fs.readFile(\"./big.file\", (err, data) => &#123;\n   if (err) throw err;\n\n   res.end(data);\n &#125;);\n&#125;);\n\nserver.listen(8000);\n\n对比电脑前后内存消耗\n &gt;\n内存消耗直接由 8.7 MB 飙升至 434.8 MB 。在我们将内容写入响应对象之前，将文件存储在内存中，这是非常低效且消耗服务器内存的，尤其在大文件场景下尤为明显（Node 是基于 V8 构建的， 而 V8 对于内存的使用有一定的限制。 在默认情况下， 64 位 的机器大概可以使用 1.4G ， 而 32 位 则为 0.7G 的大小）。\n引入主角 Stream\nconst fs = require(\"fs\");\nconst server = require(\"http\").createServer();\n\nserver.on(\"request\", (req, res) => &#123;\n const src = fs.createReadStream(\"./big.file\");\n src.pipe(res);\n&#125;);\n\nserver.listen(8000);\n\n\n内存使用量增加了大约 25MB ，仅此而已\n对于大文件的操作通常会使用 Buffer ， 究其原因就是因为 Node 中内存小的原因， 而使用 Buffer 是不受这个限制， 它是堆外内存(可通过 process.memoryUsage() 查看内存分配)\nStreamStream TypeThere are four fundamental stream types in Node: Readable , Writable , Duplex , and Transform streams .\n\nReadable - A readable stream is an abstraction for a source from which data can be consumed. An example of that is the fs.createReadStream method.\nWritable - A writable stream is an abstraction for a destination to which data can be written. An example of that is the fs.createWriteStream method.\nDuplex - A duplex stream is both Readable and Writable. An example of that is a TCP socket.\nTransform - A transform stream is basically a duplex stream that can be used to modify or transform the data as it is written and read. An example of that is the zlib.createGzip stream to compress the data using gzip. You can think of a transform stream as a function where the input is the writable stream part and the output is readable stream part. You might also hear transform streams referred to as “through streams”\n\nAll streams are instances of EventEmitter. They emit events that can be used to read and write data. However, we can consume streams data in a simpler way using the pipe method.\nStream Pipe Method\n\n\n\n\n\n\n\n\nThe pipe method is the easiest way to consume streams.管道方法是使用流的最简单方法。\n切记：通常建议使用管道方法或使用带有事件的流，但避免将这两种方法混合使用。 &gt; 即：当您使用管道方法时，您不需要使用事件，但是如果您需要以更自定义的方式使用流，那么事件就是最好的选择。\n# In this simple line, we’re piping the output of a readable stream – the source of data, as the input of a writable stream – the destination.\n# The source has to be a readable stream and the destination has to be a writable one.\nreadableSrc.pipe(writableDest);\n\n# they can both be duplex/transform streams as well. For streams readableSrc (readable), transformStream1 and transformStream2 (duplex/transform), and finalWritableDest (writable).\nreadableSrc\n  .pipe(transformStream1)\n  .pipe(transformStream2)\n  .pipe(finalWritableDest);\n\nStream EventsPipe 除了从可读流中读取数据并写入可写流中之外，内部自动处理了很多事件。比如 errors, end-of-files, and the cases when one stream is slower or faster than the other.\n以下两种方式是等效的\n# pipe\nreadable.pipe(writable)\n\n# event listener\nreadable.on(\"data\", chunk => &#123;\n  writable.write(chunk);\n&#125;);\n\nreadable.on(\"end\", () => &#123;\n  writable.end();\n&#125;);\n\n\n\n\n\nReadable Streams\nWritable Streams\n\n\n\nEvents\ndata, end, error, close, readable\ndrain, finish, error, close, pipe, unpipe\n\n\nMethods\npipe(), unpipe(), wrap(), destroy()\nwrite(), destroy(), end()\n\n\n\nread(), unshift(), resume(), pause(), isPaused(), setEncoding()\ncork(), uncork(), setDefaultEncoding()\n\n\n\n\n\n\n\n\n\n\n\nThe most important events on a readable stream are:\n\nThe data event, which is emitted whenever the stream passes a chunk of data to the consumer\n\nThe end event, which is emitted when there is no more data to be consumed from the stream.\n\n\nThe most important events on a writable stream are:\n\nThe drain event, which is a signal that the writable stream can receive more data.\n\nThe finish event, which is emitted when all data has been flushed to the underlying system.\n\n\nPaused and Flowing Modes\n\n\n\n\n\n\n\n\nReadable streams have two main modes that affect the way we can consume them:\n\nThey can be either in the paused mode\nOr in the flowing mode\n\nThose modes are sometimes referred to as pull and push modes.这两种模式有时被称为 拉模式 和 推模式 。\n默认情况下，所有可读流都以 paused mode 启动，但在需要时，它们可以轻松切换为 flowing mode，同时在必要时也可切换回 paused mode。\n\n\n\n\n\n\n\n\n\nWhen a readable stream is in the paused mode, we can use the read() method to read from the stream on demand. However, for a readable stream in the flowing mode, the data is continuously flowing and we have to listen to events to consume it.当可读流处于暂停模式时，我们可以使用 read() 方法按需读取流。然而，对于流动模式下的可读流，数据是连续流动的，我们必须监听事件才能使用它。\nIn the flowing mode, data can actually be lost if no consumers are available to handle it. This is why when we have a readable stream in flowing mode, we need a data event handler. In fact, just adding a data event handler switches a paused stream into flowing mode and removing the data event handler switches the stream back to paused mode. Some of this is done for backward compatibility with the older Node streams interface.在流动模式下，如果没有消费者来处理数据，数据实际上可能会丢失。这就是为什么当我们有一个流动模式的可读流时，我们需要一个数据事件处理程序。事实上，只需添加数据事件处理程序，即可将暂停的流切换到流动模式，删除数据事件处理程序，即可将流切换回暂停模式。其中一些是为了向后兼容旧的节点流接口。\n\n\n\n\n\n\n\n\n\nTo manually switch between these two stream modes, you can use the resume() and pause() methods.要在这两种流模式之间手动切换，可以使用 resume() 和 pause() 方法\nWhen consuming readable streams using the pipe method, we don’t have to worry about these modes as pipe manages them automatically.当使用 pipe 方法消费可读流时，我们不必担心这些模式，因为 pipe 会自动管理它们。\nImplementing StreamsImplementing a Writable Streamconst &#123; Writable &#125; = require(\"stream\");\n\nconst outStream = new Writable(&#123;\n  # This write method takes three arguments.\n  # The chunk is usually a buffer unless we configure the stream differently.\n  # The encoding argument is needed in that case, but we can usually ignore it.\n  # The callback is a function that we need to call after we’re done processing the data chunk. It’s what signals whether the write was successful or not. To signal a failure, call the callback with an error object.\n  write(chunk, encoding, callback) &#123;\n    console.log(chunk.toString());\n    callback();\n  &#125;\n&#125;);\n\nprocess.stdin.pipe(outStream);\n\nImplement a Readable Streamconst &#123; Readable &#125; = require(\"stream\");\n\nconst inStream = new Readable();\n\ninStream.push(\"ABCDEFGHIJKLM\");\ninStream.push(\"NOPQRSTUVWXYZ\");\n\ninStream.push(null); // No more data\n\ninStream.pipe(process.stdout);\n\nconst inStream = new Readable(&#123;\n  read(size) &#123;\n    this.push(String.fromCharCode(this.currentCharCode++));\n    if (this.currentCharCode > 90) &#123;\n      this.push(null);\n    &#125;\n  &#125;\n&#125;);\n\ninStream.currentCharCode = 65;\n\ninStream.pipe(process.stdout);\n\nImplementing Duplex Streamsconst &#123; Duplex &#125; = require(\"stream\");\n\nconst inoutStream = new Duplex(&#123;\n  write(chunk, encoding, callback) &#123;\n    console.log(`duplex stream write: $&#123;chunk&#125;`);\n    callback();\n  &#125;,\n\n  read(size) &#123;\n    this.push(String.fromCharCode(this.currentCharCode++));\n    if (this.currentCharCode > 90) &#123;\n      this.push(null);\n    &#125;\n  &#125;\n&#125;);\n\ninoutStream.currentCharCode = 65;\n\nprocess.stdin.pipe(inoutStream).pipe(process.stdout);\n\nImplementing Transform Streamsconst &#123; Transform &#125; = require(\"stream\");\n\nconst upperCaseTr = new Transform(&#123;\n  transform(chunk, encoding, callback) &#123;\n    this.push(chunk.toString().toUpperCase());\n    callback();\n  &#125;\n&#125;);\n\nprocess.stdin.pipe(upperCaseTr).pipe(process.stdout);\n\nStreams Object Mode\n\n\n\n\n\n\n\n\nBy default, streams expect Buffer/String values. There is an objectMode flag that we can set to have the stream accept any JavaScript object.\n# Here’s a simple example to demonstrate that. The following combination of transform streams makes a feature to map a string of comma-separated values into a JavaScript object. So \"a,b,c,d\" becomes &#123;a: b, c: d&#125;\n\nconst &#123; Transform &#125; = require(\"stream\");\n\nconst commaSplitter = new Transform(&#123;\n  readableObjectMode: true,\n\n  transform(chunk, encoding, callback) &#123;\n    this.push(\n      chunk\n        .toString()\n        .trim()\n        .split(\",\")\n    );\n    callback();\n  &#125;\n&#125;);\n\nconst arrayToObject = new Transform(&#123;\n  readableObjectMode: true,\n  writableObjectMode: true,\n  transform(chunk, encoding, callback) &#123;\n    const obj = &#123;&#125;;\n    for (let i = 0; i &lt; chunk.length; i += 2) &#123;\n      obj[chunk[i]] = chunk[i + 1];\n    &#125;\n    this.push(obj);\n    callback();\n  &#125;\n&#125;);\n\nconst objectToString = new Transform(&#123;\n  writableObjectMode: true,\n  transform(chunk, encoding, callback) &#123;\n    this.push(JSON.stringify(chunk) + \"\\n\");\n    callback();\n  &#125;\n&#125;);\n\nprocess.stdin\n  .pipe(commaSplitter)\n  .pipe(arrayToObject)\n  .pipe(objectToString)\n  .pipe(process.stdout);\n\n参考Node’s Streams想学 Node.js，stream 先有必要搞清楚Node.js 内存溢出时如何处理？Node - 内存管理和垃圾回收Node.js Writable Stream 的实现简析\n","slug":"nodejs-stream","date":"2022-03-19T10:44:57.000Z","categories_index":"","tags_index":"NodeJS","author_index":"Matrix"},{"id":"e76dee0a8c7a5ee4319d8141408a59cb","title":"webpack 打包优化","content":"webpack 打包优化我们知道 webpack 打包优化很重要，不论是优化开发体验还是优化打包速度、体积都是很有益处的\n缩小文件搜索范围优化 loader 配置include/exclude 将 node_modules 中的文件进行包括&#x2F;排除\n&#123;\n    rules: [&#123;\n        test: /\\.js$/,\n        use: &#123;\n            loader: 'babel-loader'\n        &#125;,\n        // exclude: /node_modules/,\n        include: [path.resolve(__dirname, 'src')]\n    &#125;]\n&#125;\n\n优化 module.noParse 配置如果一些第三方模块没有使用 AMD/CommonJs 规范，可以使用 noParse 来标记这个模块，这样 Webpack 在导入模块时，就不进行解析和转换，提升 Webpack 的构建速度\n&#123;\n    module: &#123;\n        //noParse: /jquery|lodash|chartjs/,\n        noParse: function(content)&#123;\n            return /jquery|lodash|chartjs/.test(content)\n        &#125;\n    &#125;\n&#125;\n\n对于 jQuery、lodash、chartjs 等一些库，庞大且没有采用模块化标准，因此我们可以选择不解析他们。\n\n\n\n\n\n\n\n\n\n注意 ⚠️：被不解析的模块文件中不应该包含 require、import 等模块语句\n优化 resolve.alias 配置alias 通过创建 import 或者 require 的别名，把原来导入模块的路径映射成一个新的导入路径；它和 resolve.modules 不同的的是，它的作用是用别名代替前面的路径，不是省略；这样的好处就是 webpack 直接会去对应别名的目录查找模块，减少了搜索时间。\n&#123;\n  resolve: &#123;\n    alias: &#123;\n      '@': path.resolve(__dirname, 'src'),\n    &#125;,\n  &#125;,\n&#125;\n\n这样我们就能通过 import Buttom from ‘@&#x2F;Button’来引入组件了；我们不光可以给自己写的模块设置别名，还可以给第三方模块设置别名：\n&#123;\n  resolve: &#123;\n    alias: &#123;\n      'vue$': isDev ? 'vue/dist/vue.runtime.js' : 'vue/dist/vue.runtime.min.js',\n    &#125;,\n  &#125;,\n&#125;\n\n我们在 import Vue from &#39;vue&#39; 时，webpack 就会帮我们去 vue 依赖包的 dist 文件下面引入对应的文件，减少了搜索 package.json 的时间\n优化 resolve.mainFields 配置mainFields 用来告诉 webpack 使用第三方模块中的哪个字段来导入模块；第三方模块中都会有一个 package.json 文件用来描述这个模块的一些属性，比如模块名(name)、版本号(version)、作者(auth)等等；其中最重要的就是有多个特殊的字段用来告诉 webpack 导入文件的位置，有多个字段的原因是因为有些模块可以同时用于多个环境，而每个环境可以使用不同的文件。\nmainFields 的默认值和当前 webpack 配置的 target 属性有关：\n\n如果 target 为 webworker 或 web（默认），mainFields 默认值为 [&quot;browser&quot;, &quot;module&quot;, &quot;main&quot;]\n如果 target 为其他（包括 node），mainFields 默认值为 [&quot;module&quot;, &quot;main&quot;]\n\n这就是说当我们 require(&#39;vue&#39;) 的时候，webpack 先去 vue 下面搜索 browser 字段，没有找到再去搜索 module 字段，最后搜索 main 字段。　　为了减少搜索的步骤，在明确第三方模块入口文件描述字段时，我们可以将这个字段设置尽量少；一般第三方模块都采用 main 字段，因此我们可以这样配置：\n&#123;\n    resolve: &#123;\n        mainFields: [\"main\"],\n    &#125;\n&#125;\n\n优化 resolve.extensions 配置extensions 字段用来在导入模块时，自动带入后缀尝试去匹配对应的文件，它的默认值是：\n&#123;\n    resolve: &#123;\n        extensions: ['.js', '.json']\n    &#125;\n&#125;\n\n也就是说我们在 require(&#39;./utils&#39;) 时，Webpack 先匹配 utils.js，匹配不到再去匹配 utils.json，如果还找不到就报错。因此 extensions 数组越长，或者正确后缀的文件越靠后，匹配的次数越多也就越耗时，因此我们可以从以下几点来优化：\n\nextensions 数组尽量少，项目中不存在的文件后缀不要列进去\n出现频率比较高的文件后缀优先放到最前面\n在代码中导入文件的时候，要尽量把后缀名带上，避免查找\n\n减少打包文件提取公共代码Webpack4 引入了 SplitChunksPlugin 插件进行公共模块的抽取；由于 webpack4 开箱即用的特性，它不用单独安装，通过 optimization.splitChunks 进行配置即可，官方给的默认配置参数如下：\nmodule.exports = &#123;\n  optimization: &#123;\n    splitChunks: &#123;\n      // 代码分割时默认对异步代码生效，all：所有代码有效，inital：同步代码有效\n      chunks: 'async',\n      // 代码分割最小的模块大小，引入的模块大于 20000B 才做代码分割\n      minSize: 20000,\n      // 代码分割最大的模块大小，大于这个值要进行代码分割，一般使用默认值\n      maxSize: 0,\n      // 引入的次数大于等于1时才进行代码分割\n      minChunks: 1,\n      // 最大的异步请求数量,也就是同时加载的模块最大模块数量\n      maxAsyncRequests: 30,\n      // 入口文件做代码分割最多分成 30 个 js 文件\n      maxInitialRequests: 30,\n      // 文件生成时的连接符\n      automaticNameDelimiter: '~',\n      enforceSizeThreshold: 5000,\n      cacheGroups: &#123;\n        vendors: &#123;\n          // 位于node_modules中的模块做代码分割\n          test: /[\\\\/]node_modules[\\\\/]/,\n          // 根据优先级决定打包到哪个组里，例如一个 node_modules 中的模块进行代码\n          priority: -10\n        &#125;,\n        // 既满足 vendors，又满足 default，那么根据优先级会打包到 vendors 组中。\n        default: &#123;\n          // 没有 test 表明所有的模块都能进入 default 组，但是注意它的优先级较低。\n          // 根据优先级决定打包到哪个组里,打包到优先级高的组里。\n          priority: -20,\n          // 如果一个模块已经被打包过了,那么再打包时就忽略这个上模块\n          reuseExistingChunk: true\n        &#125;\n      &#125;\n    &#125;\n  &#125;\n&#125;;\n\n有时候项目依赖模块比较多，vendors.js 文件会特别大，我们还可以对它进一步拆分，按照模块划分：\n\n&#123;\n  //省略其他配置\n  cacheGroups: &#123;\n    //涉及vue的模块\n    vue: &#123;\n      test: /[\\\\/]node_modules[\\\\/](vue|vuex|vue-router)/,\n      priority: 10,\n      name: 'vue'\n    &#125;,\n    //其他模块\n    vendors: &#123;\n      test: /[\\\\/]node_modules[\\\\/]/,\n      priority: 9,\n      name: 'vendors'\n    &#125;,\n    common: &#123;\n      test: /[\\\\/]src[\\\\/]/,\n      priority: 5,\n      name: 'common'\n    &#125;\n  &#125;\n&#125;\n\n动态链接 DllPluginDLL 即动态链接库（Dynamic-Link Library）的缩写，熟悉 Windows 系统的童鞋在电脑中也经常能看到后缀是 dll 的文件，偶尔电脑弹框警告也是因为电脑中缺失了某些 dll 文件；DLL 最初用于节约应用程序所需的磁盘和内存空间，当多个程序使用同一个函数库时，DLL 可以减少在磁盘和内存中加载代码的重复量，有助于代码的复用。　　在 Webpack 中也引入了 DLL 的思想，把我们用到的模块抽离出来，打包到单独的动态链接库中去，一个动态链接库中可以有多个模块；当我们在多个页面中用到某一个模块时，不再重复打包，而是直接去引入动态链接库中的模块。　　 Webpack 中集成了对动态链接库的支持，主要用到的两个插件：\n\nDllPlugin：创建动态链接库文件\nDllReferencePlugin：在主配置中引入打包好的动态链接库文件\n\n我们首先使用 DllPlugin 来创建动态链接库文件，在项目下新建 webpack.dll.js 文件：\nconst path = require(\"path\");\nconst webpack = require(\"webpack\");\n\nmodule.exports = &#123;\n  mode: \"production\",\n  entry: &#123;\n    vue: [\"vue\", \"vuex\", \"vue-router\"],\n    vendor: [\"dayjs\", \"axios\", \"mint-ui\"],\n  &#125;,\n  output: &#123;\n    path: path.resolve(__dirname, \"public/vendor\"),\n    // 指定文件名\n    filename: \"[name].dll.js\",\n    //暴露全局变量的名称\n    library: \"[name]_dll_lib\",\n  &#125;,\n  plugins: [\n    new webpack.DllPlugin(&#123;\n      path: path.join(__dirname, \"public\", \"vendor\", \"[name].manifest.json\"),\n      name: \"[name]_dll_lib\",\n    &#125;),\n  ],\n&#125;;\n\n这里 entry 设置了多个入口，每个入口也有多个模块文件；然后在 package.json 添加打包命令\n&#123;\n    \"scripts\":&#123;\n        \"build:dll\": \"webpack --config=webpack.dll.js\"\n    &#125;\n&#125;\n\n执行 npm run build:dll 后，我们在 /public/vendor 目录下得到了我们打包后的动态链接库的文件：\n├── vendor.dll.js\n├── vendor.manifest.json\n├── vue.dll.js\n└── vue.manifest.json\n\n生成出来的打包文件正好是以两个入口名来命名的，以 vue 为例，看一下 vue.dll.js 的内容：\nvar vue_dll_lib =\n/******/ (function(modules) &#123;\n    // 省略webpackBootstrap代码\n/******/ &#125;)\n/******/ (&#123;\n\n/***/ \"./node_modules/vue-router/dist/vue-router.esm.js\":\n/***/ (function(module, exports, __webpack_require__) &#123;\n    // 省略vue-router模块代码\n/***/ &#125;),\n\n/***/ \"./node_modules/vue/dist/vue.runtime.esm.js\":\n/***/ (function(module, exports, __webpack_require__) &#123;\n    // 省略vue模块代码\n/***/ &#125;),\n\n/***/ \"./node_modules/vuex/dist/vuex.esm.js\":\n/***/ (function(module, exports, __webpack_require__) &#123;\n    // 省略vuex模块代码\n/***/ &#125;),\n\n/******/ &#125;);\n\n可以看出，动态链接库中包含了引入模块的所有代码，这些代码存在一个对象中，通过模块路径作为键名来进行引用；并且通过 vue_dll_lib 暴露到全局；vue.manifest.json 则是用来描述动态链接库文件中包含了哪些模块：\n&#123;\n    \"name\": \"vue_dll_lib\",\n    \"content\": &#123;\n        \"./node_modules/vue-router/dist/vue-router.esm.js\": &#123;\n            \"id\": \"./node_modules/vue-router/dist/vue-router.esm.js\",\n            \"buildMeta\": &#123;&#125;\n        &#125;,\n        \"./node_modules/vue/dist/vue.runtime.esm.js\": &#123;\n            \"id\": \"./node_modules/vue/dist/vue.runtime.esm.js\",\n            \"buildMeta\": &#123;&#125;\n        &#125;,\n        \"./node_modules/vuex/dist/vuex.esm.js\": &#123;\n            \"id\": \"./node_modules/vuex/dist/vuex.esm.js\",\n            \"buildMeta\": &#123;&#125;\n        &#125;,\n    &#125;\n&#125;\n\nmanifest.json 描述了对应 js 文件包含哪些模块，以及对应模块的键名（id），这样我们在模板页面中就可以将动态链接库作为外链引入，当 Webpack 解析到对应模块时就通过全局变量来获取模块：\n&lt;!-- public/index.html -->\n&lt;!DOCTYPE html>\n&lt;html lang=\"en\">\n&lt;head>\n    &lt;meta charset=\"UTF-8\">\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    &lt;title>Document&lt;/title>\n&lt;/head>\n&lt;body>\n    &lt;div id=\"app\">&lt;/div>\n    &lt;!-- 引入动态链接库 -->\n    &lt;script src=\"./vendor/vendor.dll.js\">&lt;/script>\n    &lt;script src=\"./vendor/vue.dll.js\">&lt;/script>\n&lt;/body>\n&lt;/html>\n\n最后我们在打包时，通过 DllReferencePlugin 将动态链接库引入到主配置中：\n//webpack.config.js\n&#123;\n    plugins: [\n        new webpack.DllReferencePlugin(&#123;\n            context: path.join(__dirname),\n            manifest: require('./public/vendor/vendor.manifest.json')\n        &#125;),\n        new webpack.DllReferencePlugin(&#123;\n            context: path.join(__dirname),\n            manifest: require('./public/vendor/vue.manifest.json')\n        &#125;),\n    ]\n&#125;\n\n\n\n\n\n\n\n\n\n\n注意 ⚠️：动态链接库打包到 /public/vendor 目录下，还需要通过 CopyWebpackPlugin 插件将它拷贝到生成后的目录中，否则会出现引用失败的报错；打包动态链接库文件只需要执行一次，除非以后模块升级或者引入新的模块。\nexternals我们在项目打包时，有一些第三方的库会从 CDN 引入（比如 jQuery 等），如果在 bundle 中再次打包项目就过于臃肿，我们就可以通过配置 externals 将这些库在打包的时候排除在外。\n&#123;\n  externals: &#123;\n    'jquery': \"jQuery\",\n    'react': 'React',\n    'react-dom': 'ReactDOM',\n    'vue': 'Vue'\n  &#125;\n&#125;\n\n这样就表示当我们遇到 require(&#39;jquery&#39;) 时，从全局变量去引用 jQuery，其他几个包也同理；这样打包时就把 jquery、react、vue 和 react-dom 从 bundle 中剔除了。\nTree ShakingTree Shaking 最早由 rollup 实现，后来 webpack2 也实现了这项功能；Tree Shaking 的字面意思是摇树，一棵树上有一些树叶虽然还挂着，但是它可能已经死掉了，通过摇树方式把这些死掉的树叶去除。\n为了让 Tree Shaking 生效，我们需要使用 ES6 模块化的语法，因为 ES6 模块语法是静态化加载模块，它有以下特点：\n\n静态加载模块，效率比 CommonJS 模块的加载方式高\nES6 模块是编译时加载，使得静态分析成为可能进一步拓宽 JS 的语法\n\n如果是 require，在运行时确定模块，那么将无法去分析模块是否可用，只有在编译时分析，才不会影响运行时的状态。\n使用 ES6 模块后还有一个问题，因为我们的代码一般都采用 babel 进行编译，而 babel 的 preset 默认会将任何模块类型编译成 Commonjs，因此我们还需要修改 .babelrc 配置文件：\n&#123;\n  \"presets\": [\n    [\n      \"@babel/preset-env\",\n      &#123;\n        // 添加modules：false\n        \"modules\": false\n      &#125;\n    ]\n  ]\n&#125;\n\n配置好 babel 后我们需要让 webpack 先将“死代码”标识出来：\n&#123;\n  // 其他配置\n  optimization: &#123;\n    usedExports: true,\n    sideEffects: true,\n  &#125;\n&#125;\n\n运行打包命令后，当我们打开输出的 bundle 文件时，我们发现虽然一些“死代码”还存在里面，但是加上了一个 unused harmony export 的标识\n/* unused harmony export isFunction */\n/* unused harmony export isDate */\nvar toString = Object.prototype.toString;\nfunction isFunction(val) &#123;\n  return toString.call(val) === '[object Function]';\n&#125;\nfunction isDate(val) &#123;\n  return toString.call(val) === '[object Date]';\n&#125;\n\n虽然 webpack 给我们指出了哪些函数用不上，但是还需要我们通过插件来剔除；由于 uglifyjs-webpack-plugin 不支持 ES6 语法，这里我们使用 terser-webpack-plugin 的插件来代替它：\nconst TerserJSPlugin = require(\"terser-webpack-plugin\");\nmodule.exports = &#123;\n  optimization: &#123;\n    usedExports: true,\n    sideEffects: true,\n    minimize: true,\n    minimizer: [\n      new TerserJSPlugin(&#123;\n        cache: true,\n        parallel: true,\n        sourceMap: false,\n      &#125;),\n    ],\n  &#125;\n&#125;\n\n这样我们发现打包出来的文件就没有多余的代码了。\n\n\n\n\n\n\n\n\n\nTree Shaking 在生产环境（production）是默认开启的对于我们常用的一些第三方模块，我们也可以实现 Tree Shaking；以 lodash 为例，它整个包有非常多的函数，但并不是所有的函数都是我们所用到的，因此我们也需要对它没有用到的代码进行剔除。\n//index.js\nimport &#123; chunk &#125; from 'lodash'\nconsole.log(chunk([1,2,3,4], 2))\n\n打包出来发现包的大小还是能达到 70+kb，如果只引用了 chunk 不应该有这么大；我们打开 /node_modules/lodash/index.js 发现他还是使用了 require 的模式导入导出模块，因此导致 Tree Shaking 失败；我们先安装使用 ES6 模块版本的 lodash：npm i -S lodash-es，然后修改引入包：\n//index.js\nimport &#123; chunk &#125; from 'lodash-es'\nconsole.log(chunk([1,2,3,4], 2))\n缓存我们知道 webpack 会对不同的文件调用不同的 loader 进行解析处理，解析的过程也是最耗性能的过程；我们每次改代码也只是修改项目中的少数文件，项目中的大部分文件改动的次数不是那么频繁；那么如果我们将解析文件的结果缓存下来，下次发现同样的文件只需要读取缓存就能极大的提升解析的性能。\ncache-loadercache-loader 可以将一些对性能消耗比较大的 loader 生产的结果缓存在磁盘中，等下次再次打包时如果是相同的代码就可以直接读取缓存，减少性能消耗。\n\n\n\n\n\n\n\n\n\n注意 ⚠️：保存和读取缓存也会产生额外的性能开销，因此 cache-loader 适合用于对性能消耗较大的 loader，否则反而会增加性能消耗\ncache-loader 的使用也非常简单，安装后在所需要缓存的 loader 前面添加即可（因为 loader 加载的顺序是反向的），比如我们需要给 babel-loader 添加缓：\n&#123;\n  //省略其他代码\n  rules: [\n    &#123;\n      test: /\\.js/,\n      use: [\n        &#123;\n          loader: 'cache-loader'\n        &#125;,\n        &#123;\n          loader: \"babel-loader\",\n        &#125;,\n      ],\n    &#125;,\n  ],\n&#125;\n\n然而我们发现第一次打包的速度并没有发生明显变化，甚至可能还比原来打包的更慢了；同时还多了 /node_modules/.cache/cache-loader/ 这个目录，看名字就是一个缓存文件；但是从第二次打包开始，直接减少了 75% 的耗时\nHardSourceWebpackPluginHardSourceWebpackPlugin 也可以为模块提供缓存功能，同时也是将文件缓存在磁盘中\n首先通过 npm i -D hard-source-webpack-plugin 来安装插件，并且在配置中添加插件：\nvar HardSourceWebpackPlugin =\n    require('hard-source-webpack-plugin');\nmodule.exports = &#123;\n  plugins: [\n    new HardSourceWebpackPlugin()\n  ]\n&#125;\n\n一般 HardSourceWebpackPlugin 默认缓存是在 /node_modules/.cache/hard-source/[hash] 目录下，我们可以设置它的缓存目录和何时创建新的缓存哈希值。\nmodule.exports = &#123;\n  plugins: [\n    new HardSourceWebpackPlugin(&#123;\n      //设置缓存目录的路径\n      //相对路径或者绝对路径\n      cacheDirectory: 'node_modules/.cache/hard-source/[confighash]',\n      //构建不同的缓存目录名称\n      //也就是cacheDirectory中的[confighash]值\n      configHash: function(webpackConfig) &#123;\n        return require('node-object-hash')(&#123;sort: false&#125;).hash(webpackConfig);\n      &#125;,\n      //环境hash\n      //当loader、plugin或者其他npm依赖改变时进行替换缓存\n      environmentHash: &#123;\n        root: process.cwd(),\n        directories: [],\n        files: ['package-lock.json', 'yarn.lock'],\n      &#125;,\n      //自动清除缓存\n      cachePrune: &#123;\n        //缓存最长时间（默认2天）\n        maxAge: 2 * 24 * 60 * 60 * 1000,\n        //所有的缓存大小超过size值将会被清除\n        //默认50MB\n        sizeThreshold: 50 * 1024 * 1024\n      &#125;,\n    &#125;)\n  ]\n&#125;\n\n参考Webpack 配置全解析（优化篇）带你深度解锁 Webpack 系列(优化篇)Webpack 官方文档 - Tree Shaking\n","slug":"webpack-bundle-optimization","date":"2022-02-23T10:57:14.000Z","categories_index":"","tags_index":"webpack","author_index":"Matrix"},{"id":"82dcbf1a43d49c4fc7ea77c32662c2c0","title":"webpack 之 LoaderRunner 源码解读","content":"回顾 webpack 构建编译我们知道，webpack 整个的编译过程\n\n\n\n\n\n\n\n\n\ncompiler.run -&gt; [beforeRun hook -&gt; run hook] -&gt; compiler.compile -&gt; [beforeCompile hook -&gt; compile hook] -&gt; compiler.newCompilation(params) -&gt; [make hook] -&gt; compilation.finish -&gt; compilation.seal -&gt; [afterCompile hook]\n其中最核心的编译阶段是 make hook 的触发调用。而订阅 make hook 的 plugin 为 SingleEntryPlugin、MultiEntryPlugin、DynamicEntryPlugin。通过 SingleEntryPlugin 等 plugin 作为构建的入口起始点，即从入口文件开始构建编译。\nmake hook 触发后将执行 compilation.addEntry -&gt; compilation._addModuleChain -&gt; buildModule -&gt; module.build -&gt; module.doBuild -&gt; runLoaders\n即从入口文件开始进行构建打包，实际的构建处理是通过调用 runLoaders 实现。\nloader-runner 功能执行流程 normal 和 pitch一个 loader 可以定义两类函数，一个默认导出的函数 normalLoader，一个用于阻断常规流程的函数 pitchLoader\n// a-loader.js\n// normal loader:\nfunction aLoader(resource) &#123;\n    // ...\n    return resource\n&#125;\n// pitch loader:\naLoader.pitch = function() &#123;&#125;\nmodule.exports = aLoader\n\n如果我们配置 use: [ &#39;a-loader&#39;, &#39;b-loader&#39;, &#39;c-loader&#39; ]，且三个 loader 都没有 pitchLoader 或 pitchLoader 无返回值，loader 将会以以下流程执行：\n// |- a-loader `pitch` 没有或无返回值\n//   |- b-loader `pitch` 没有或无返回值\n//     |- c-loader `pitch` 没有或无返回值\n//       |- load resource\n//     |- c-loader normal execution\n//   |- b-loader normal execution\n// |- a-loader normal execution\n\n如果在 b-loader 的 pitch 函数返回了某个值，流程将会变成下面这样：\n// |- a-loader `pitch`\n//   |- b-loader `pitch` 有返回值\n// |- a-loader normal execution\n\n支持同步&#x2F;异步loader 可以支持以同步或异步(callback, Promise)方式运行，调用 this.async() 获取回调，并在执行完毕后调用。\nmodule.exports = function(resource) &#123;\n    const callback = this.async()\n    asyncFunc((err, res) => &#123;\n        callback(err, res)\n    &#125;)\n&#125;\n\nloader.raw通过这个参数指定 loader 接收一个 buffer 类型的资源或 string 类型的资源\nloader-runner 核心源码解析runLoaders 入口函数function runLoaders(options, callback) &#123;\n  // 定义上下文\n  var loaderContext = options.context || &#123;&#125;;\n  // 待解析的文件\n  loaderContext.resourcePath = options.resource;\n  // 待解析文件的目录\n  loaderContext.context = dirname(options.resource);\n  // 当前执行到第几个loader\n  loaderContext.loaderIndex = 0;\n  // 创建loader对象\n  loaderContext.loaders = options.loaders\n\n  // 执行Pitch阶段\n\tvar processOptions = &#123;\n\t\tresourceBuffer: null,\n\t\treadResource: fs.readFile.bind(fs),\n\t&#125;;\n  iteratePitchingLoaders(processOptions, loaderContext, (err, res) => &#123;\n\t\tcallback(null, &#123;\n      // 最后经过loader输出的值，可能为buffer或string\n      result: result,\n      // 最原始的资源buffer\n      resourceBuffer: processOptions.resourceBuffer,\n      // 是否需要缓存结果\n      cacheable: requestCacheable,\n      // loader需要监听的文件\n      fileDependencies: fileDependencies,\n      // loader需要监听的文件夹\n      contextDependencies: contextDependencies\n\t\t&#125;);\n  &#125;)\n&#125;\n\niteratePitchingLoaders这里采用了递归的方法来处理 loader 链式操作，当 pitch 都执行完开始加载资源，当 pitch 有返回值直接跳过加载资源，往回执行 normalLoader\nfunction iteratePitchingLoaders(options, loaderContext, callback) &#123;\n  // 如果所有loader的pitch都执行完，就开始执行 processResource 并进行处理源文件\n\tif(loaderContext.loaderIndex >= loaderContext.loaders.length) &#123;\n    return processResource(options, loaderContext, callback);\n  &#125;\n\n\tvar loader = loaderContext.loaders[loaderContext.loaderIndex];\n\n\t// 奇葩的递归执行操作，循环递增条件放在这里\n\tif(loader.pitchExecuted) &#123;\n\t\tloaderContext.loaderIndex++;\n\t\treturn iteratePitchingLoaders(options, loaderContext, callback);\n  &#125;\n\n  // 加载执行loader.pitch\n\tloadLoader(loader, function(err) &#123;\n\t\tvar fn = loader.pitch;\n\t\tloader.pitchExecuted = true;\n\t\tif(!fn) return iteratePitchingLoaders(options, loaderContext, callback);\n\n    runSyncOrAsync(fn, loaderContext, [loaderContext.remainingRequest,  loaderContext.previousRequest, loader.data = &#123;&#125;], function(err) &#123;\n      if(err) return callback(err);\n      var args = Array.prototype.slice.call(arguments, 1);\n      // pitch有返回值，直接跳过后面的loader，并把返回值给其他loader\n      if(args.length > 0) &#123;\n        loaderContext.loaderIndex--;\n        iterateNormalLoaders(options, loaderContext, args, callback);\n      &#125; else &#123;\n        iteratePitchingLoaders(options, loaderContext, callback);\n      &#125;&#125;\n    )&#125;\n  );\n&#125;\n\nprocessResource这里会加载待处理的资源文件，并将其加入到文件监听中，然后开始执行 normalLoadr：\nfunction processResource(options, loaderContext, callback) &#123;\n\tloaderContext.loaderIndex = loaderContext.loaders.length - 1;\n\n\tvar resourcePath = loaderContext.resourcePath;\n\tif(resourcePath) &#123;\n\t\tloaderContext.addDependency(resourcePath);\n\t\toptions.readResource(resourcePath, function(err, buffer) &#123;\n\t\t\tif(err) return callback(err);\n\t\t\toptions.resourceBuffer = buffer;\n\t\t\titerateNormalLoaders(options, loaderContext, [buffer], callback);\n\t\t&#125;);\n\t&#125; else &#123;\n\t\titerateNormalLoaders(options, loaderContext, [null], callback);\n\t&#125;\n&#125;\n\niterateNormalLoaders这里递归执行 normalLoader，在执行前会进行资源类型的转换\nfunction iterateNormalLoaders(options, loaderContext, args, callback) &#123;\n  // 所有loader执行完毕\n\tif(loaderContext.loaderIndex &lt; 0)\n\t\treturn callback(null, args);\n\n\tvar currentLoaderObject = loaderContext.loaders[loaderContext.loaderIndex];\n\n\t// iterate\n\tif(currentLoaderObject.normalExecuted) &#123;\n\t\tloaderContext.loaderIndex--;\n\t\treturn iterateNormalLoaders(options, loaderContext, args, callback);\n\t&#125;\n\n\tvar fn = currentLoaderObject.normal;\n  // 标记当前loader已执行过\n\tcurrentLoaderObject.normalExecuted = true;\n\tif(!fn) &#123;\n\t\treturn iterateNormalLoaders(options, loaderContext, args, callback);\n\t&#125;\n\n\tconvertArgs(args, currentLoaderObject.raw);\n\n\trunSyncOrAsync(fn, loaderContext, args, function(err) &#123;\n\t\tif(err) return callback(err);\n\n\t\tvar args = Array.prototype.slice.call(arguments, 1);\n\t\titerateNormalLoaders(options, loaderContext, args, callback);\n\t&#125;);\n&#125;\n\n执行 runSyncOrAsync 之前，通过调用 convertArgs 以及当前 loader 配置的 raw 值来决定是否将上一个 loader 传入的 result 转化为 buffer\nfunction convertArgs(args, raw) &#123;\n\tif(!raw &amp;&amp; Buffer.isBuffer(args[0]))\n\t\targs[0] = utf8BufferToString(args[0]);\n\telse if(raw &amp;&amp; typeof args[0] === \"string\")\n\t\targs[0] = new Buffer(args[0], \"utf-8\"); // eslint-disable-line\n&#125;\n\nrunSyncOrAsync函数内部的 isSync 和 isDone 很重要，isSync 是来控制同步还是异步 loader 的，isDone 是防止 callback 被触发多次。context.async 是一个闭包函数，它返回的是 innerCallback，而 innerCallback 内部才是真正执行 runSyncOrAsync 的 callback 函数，这个 callback 会进入下一次的 iterateNormalLoaders 逻辑。同时 innerCallback 也是 context.callback 的一个引用。真正执行 loader 的 normal 的函数语句在下面的这个立即执行函数里面。\nfunction runSyncOrAsync(fn, context, args, callback) &#123;\n\tvar isSync = true;\n\tvar isDone = false;\n\tvar isError = false; // internal error\n\tvar reportedError = false;\n\tcontext.async = function async() &#123;\n\t\tif(isDone) &#123;\n\t\t\tif(reportedError) return;\n\t\t\tthrow new Error('async(): The callback was already called.');\n\t\t&#125;\n\t\tisSync = false;\n\t\treturn innerCallback;\n\t&#125;;\n\tvar innerCallback = context.callback = function() &#123;\n\t\tif(isDone) &#123;\n\t\t\tif(reportedError) return;\n\t\t\tthrow new Error('callback(): The callback was already called.');\n\t\t&#125;\n\t\tisDone = true;\n\t\tisSync = false;\n\t\ttry &#123;\n\t\t\tcallback.apply(null, arguments);\n\t\t&#125; catch(e) &#123;\n\t\t\tisError = true;\n\t\t\tthrow e;\n\t\t&#125;\n\t&#125;;\n\ttry &#123;\n\t\tvar result = (function LOADER_EXECUTION() &#123;\n\t\t\treturn fn.apply(context, args);\n\t\t&#125;());\n\t\tif(isSync) &#123;\n\t\t\tisDone = true;\n\t\t\tif(result === undefined)\n\t\t\t\treturn callback();\n\t\t\tif(result &amp;&amp; typeof result === \"object\" &amp;&amp; typeof result.then === \"function\") &#123;\n\t\t\t\treturn result.then(function(r) &#123;\n\t\t\t\t\tcallback(null, r);\n\t\t\t\t&#125;, callback);\n\t\t\t&#125;\n\t\t\treturn callback(null, result);\n\t\t&#125;\n\t&#125; catch(e) &#123;\n\t\tif(isError) throw e;\n\t\tif(isDone) &#123;\n\t\t\t// loader is already \"done\", so we cannot use the callback function\n\t\t\t// for better debugging we print the error on the console\n\t\t\tif(typeof e === \"object\" &amp;&amp; e.stack) console.error(e.stack);\n\t\t\telse console.error(e);\n\t\t\treturn;\n\t\t&#125;\n\t\tisDone = true;\n\t\treportedError = true;\n\t\tcallback(e);\n\t&#125;\n&#125;\n\n参考webpack 之 LoaderRunner 全方位揭秘Webpack 源码分析 - loader-runnergithub loader-runner\n","slug":"webpack-loader-runner","date":"2022-02-22T17:27:27.000Z","categories_index":"","tags_index":"Webpack","author_index":"Matrix"},{"id":"670e37e7b17df0fce5e221bac0d0bce1","title":"Webpack 构建编译阶段","content":"Webpack 核心之构建编译调用 compiler.run 方法来启动构建\nrun(callback) &#123;\n    // 编译结束回调函数\n    const onCompiled = (err, compilation) => &#123;\n    \tthis.hooks.done.callAsync(stats, err => &#123;\n    \t\treturn finalCallback(null, stats);\n    \t&#125;);\n    &#125;;\n\n    // 执行订阅了 compiler.beforeRun 钩子插件的回调\n    this.hooks.beforeRun.callAsync(this, err => &#123;\n        // 执行订阅了 compiler.run 钩子插件的回调\n    \tthis.hooks.run.callAsync(this, err => &#123;\n    \t\tthis.compile(onCompiled);\n    \t&#125;);\n    &#125;);\n&#125;\n\ncompiler.compile 开始真正执行我们的构建流程，在 compile 阶段，Compiler 对象会开始实例化两个核心的工厂对象，分别是 NormalModuleFactory 和 ContextModuleFactory。工厂对象顾名思义就是用来创建实例的，它们后续用来创建 module 实例的，包括 NormalModule 以及 ContextModule 实例。\ncompile(callback) &#123;\n    // 实例化核心工厂对象\n    const params = this.newCompilationParams();\n    // 执行订阅了 compiler.beforeCompile 钩子插件的回调\n    this.hooks.beforeCompile.callAsync(params, err => &#123;\n        // 执行订阅了 compiler.compile 钩子插件的回调\n        this.hooks.compile.call(params);\n        // 创建此次编译的 `Compilation` 对象\n        const compilation = this.newCompilation(params);\n\n        // 执行订阅了 compiler.make 钩子插件的回调\n        this.hooks.make.callAsync(compilation, err => &#123;\n\n            compilation.finish(err => &#123;\n                compilation.seal(err => &#123;\n                    this.hooks.afterCompile.callAsync(compilation, err => &#123;\n                \t\treturn callback(null, compilation);\n                \t&#125;);\n                &#125;)\n            &#125;)\n        &#125;)\n    &#125;)\n&#125;\n\n在讲 this.hooks.make.callAsync 之前不得不提，make hook 实际是在 SingleEntryPlugin 进行注册的。\n编译构建阶段SingleEntryPlugin -&gt; compilation.addEntry在 lib/WebpackOptionsApply.js 中注册 EntryOptionPlugin，并立即执行 compiler.hooks.entryOption.call()\nnew EntryOptionPlugin().apply(compiler);\ncompiler.hooks.entryOption.call(options.context, options.entry);\n\n在 lib/EntryOptionPlugin.js 中注册了 entryOption hook，无论是 SingleEntryPlugin、MultiEntryPlugin 还是 DynamicEntryPlugin 均是注册了 make hook。\nconst itemToPlugin = (context, item, name) => &#123;\n\tif (Array.isArray(item)) &#123;\n\t\treturn new MultiEntryPlugin(context, item, name);\n\t&#125;\n\treturn new SingleEntryPlugin(context, item, name);\n&#125;;\n\nmodule.exports = class EntryOptionPlugin &#123;\n\tapply(compiler) &#123;\n\t\tcompiler.hooks.entryOption.tap(\"EntryOptionPlugin\", (context, entry) => &#123;\n\t\t\tif (typeof entry === \"string\" || Array.isArray(entry)) &#123;\n\t\t\t\titemToPlugin(context, entry, \"main\").apply(compiler);\n\t\t\t&#125; else if (typeof entry === \"object\") &#123;\n\t\t\t\tfor (const name of Object.keys(entry)) &#123;\n\t\t\t\t\titemToPlugin(context, entry[name], name).apply(compiler);\n\t\t\t\t&#125;\n\t\t\t&#125; else if (typeof entry === \"function\") &#123;\n\t\t\t\tnew DynamicEntryPlugin(context, entry).apply(compiler);\n\t\t\t&#125;\n\t\t\treturn true;\n\t\t&#125;);\n\t&#125;\n&#125;;\n\n以 SingleEntryPlugin 为例，make hook 注册于此，即当 compiler.compile 中执行 this.hooks.make.callAsync，实际会触发执行 compilation.addEntry，即真正的编译于此处开启。\nclass SingleEntryPlugin &#123;\n\t/**\n\t * An entry plugin which will handle\n\t * creation of the SingleEntryDependency\n\t *\n\t * @param &#123;string&#125; context context path\n\t * @param &#123;string&#125; entry entry path\n\t * @param &#123;string&#125; name entry key name\n\t */\n\tconstructor(context, entry, name) &#123;\n\t\tthis.context = context;\n\t\tthis.entry = entry;\n\t\tthis.name = name;\n\t&#125;\n\n\t/**\n\t * @param &#123;Compiler&#125; compiler the compiler instance\n\t * @returns &#123;void&#125;\n\t */\n\tapply(compiler) &#123;\n\t\tcompiler.hooks.compilation.tap(\n\t\t\t\"SingleEntryPlugin\",\n\t\t\t(compilation, &#123; normalModuleFactory &#125;) => &#123;\n\t\t\t\tcompilation.dependencyFactories.set(\n\t\t\t\t\tSingleEntryDependency,\n\t\t\t\t\tnormalModuleFactory\n\t\t\t\t);\n\t\t\t&#125;\n\t\t);\n\n\t\tcompiler.hooks.make.tapAsync(\n\t\t\t\"SingleEntryPlugin\",\n\t\t\t(compilation, callback) => &#123;\n\t\t\t\tconst &#123; entry, name, context &#125; = this;\n\n\t\t\t\tconst dep = SingleEntryPlugin.createDependency(entry, name);\n\t\t\t\tcompilation.addEntry(context, dep, name, callback);\n\t\t\t&#125;\n\t\t);\n\t&#125;\n\n\t/**\n\t * @param &#123;string&#125; entry entry request\n\t * @param &#123;string&#125; name entry name\n\t * @returns &#123;SingleEntryDependency&#125; the dependency\n\t */\n\tstatic createDependency(entry, name) &#123;\n\t\tconst dep = new SingleEntryDependency(entry);\n\t\tdep.loc = &#123; name &#125;;\n\t\treturn dep;\n\t&#125;\n&#125;\n\ncompilation.addEntry -&gt; _addModuleChain_addModuleChain 中接收参数 dependency 传入的入口依赖，使用对应的工厂函数 NormalModuleFactory.create 方法生成一个空的 module 对象，回调中会把此 module 存入 compilation.modules 对象和 dependencies.module 对象中，由于是入口文件，也会存入 compilation.entries 中。随后执行 buildModule 进入真正的构建 module 内容的过程。\n_addModuleChain(context, dependency, onModule, callback) &#123;\n    // ...\n\n    // 根据依赖查找对应的工厂函数\n    const Dep = /** @type &#123;DepConstructor&#125; */ (dependency.constructor);\n    const moduleFactory = this.dependencyFactories.get(Dep);\n\n    this.semaphore.acquire(() => &#123;\n        moduleFactory.create(\n            &#123;\n                dependencies: [dependency]\n                ...\n            &#125;,\n            (err, module) => &#123;\n                // ...\n\n                const afterBuild = () => &#123;\n                    if (addModuleResult.dependencies) &#123;\n                        this.processModuleDependencies(module, err => &#123;\n                            if (err) return callback(err);\n                            callback(null, module);\n                        &#125;);\n                    &#125; else &#123;\n                        return callback(null, module);\n                    &#125;\n                &#125;;\n\n\n                if (addModuleResult.build) &#123;\n                    this.buildModule(module, false, null, null, err => &#123;\n                        if (err) &#123;\n                            this.semaphore.release();\n                            return errorAndCallback(err);\n                        &#125;\n\n                        if (currentProfile) &#123;\n                            const afterBuilding = Date.now();\n                            currentProfile.building = afterBuilding - afterFactory;\n                        &#125;\n\n                        this.semaphore.release();\n                        afterBuild();\n                    &#125;);\n                &#125;\n            &#125;\n        );\n    &#125;);\n&#125;\n\n_addModuleChain -&gt; runLoadersbuildModule 方法主要执行 module.build()，对应的是 NormalModule.build()，实际调用 doBuild\n// NormalModule.js\nbuild(options, compilation, resolver, fs, callback) &#123;\n    return this.doBuild(options, compilation, resolver, fs, err => &#123;\n        ...\n    &#125;\n&#125;\n\n一句话说，doBuild 调用了相应的 loaders ，把我们的模块转成标准的 JS 模块。这里，使用 babel-loader 来编译 index.js ，source 就是 babel-loader 编译后的代码。runLoaders 实际为 loader-runner 模块导出函数。\ndoBuild(options, compilation, resolver, fs, callback) &#123;\n    const loaderContext = this.createLoaderContext(\n        resolver,\n        options,\n        compilation,\n        fs\n    );\n\n    runLoaders(\n        &#123;\n            resource: this.resource,\n            loaders: this.loaders,\n            context: loaderContext,\n            readResource: fs.readFile.bind(fs)\n        &#125;,\n        (err, result) => &#123;\n            if (result) &#123;\n                this.buildInfo.cacheable = result.cacheable;\n                this.buildInfo.fileDependencies = new Set(result.fileDependencies);\n                this.buildInfo.contextDependencies = new Set(\n                    result.contextDependencies\n                );\n            &#125;\n\n            if (err) &#123;\n                if (!(err instanceof Error)) &#123;\n                    err = new NonErrorEmittedError(err);\n                &#125;\n                const currentLoader = this.getCurrentLoader(loaderContext);\n                const error = new ModuleBuildError(this, err, &#123;\n                    from:\n                        currentLoader &amp;&amp;\n                        compilation.runtimeTemplate.requestShortener.shorten(\n                            currentLoader.loader\n                        )\n                &#125;);\n                return callback(error);\n            &#125;\n\n            const resourceBuffer = result.resourceBuffer;\n            const source = result.result[0];\n            const sourceMap = result.result.length >= 1 ? result.result[1] : null;\n            const extraInfo = result.result.length >= 2 ? result.result[2] : null;\n\n            if (!Buffer.isBuffer(source) &amp;&amp; typeof source !== \"string\") &#123;\n                const currentLoader = this.getCurrentLoader(loaderContext, 0);\n                const err = new Error(\n                    `Final loader ($&#123;\n                        currentLoader\n                            ? compilation.runtimeTemplate.requestShortener.shorten(\n                                    currentLoader.loader\n                                )\n                            : \"unknown\"\n                    &#125;) didn't return a Buffer or String`\n                );\n                const error = new ModuleBuildError(this, err);\n                return callback(error);\n            &#125;\n\n            this._source = this.createSource(\n                this.binary ? asBuffer(source) : asString(source),\n                resourceBuffer,\n                sourceMap\n            );\n            this._sourceSize = null;\n            this._ast =\n                typeof extraInfo === \"object\" &amp;&amp;\n                extraInfo !== null &amp;&amp;\n                extraInfo.webpackAST !== undefined\n                    ? extraInfo.webpackAST\n                    : null;\n            return callback();\n        &#125;\n    );\n&#125;\n\n经过 doBuild 之后，我们的任何模块都被转成了标准的 JS 模块\n\n参考webpack 构建流程分析\n","slug":"webpack-stage-compiler","date":"2022-02-21T13:12:08.000Z","categories_index":"","tags_index":"Webpack","author_index":"Matrix"},{"id":"2f91216609991253bb8453ebedd72331","title":"Webpack 初始化阶段","content":"Webpack 核心之初始化\n\n\n\n\n\n\n\n\nWebpack 核心功能官方解释At its core, webpack is a static module bundler for modern JavaScript applications.将各种类型的资源，包括图片、css、js 等，转译、组合、拼接、生成 JS 格式的 bundler 文件\n\nWebpack 初始化核心代码\n\n\n\n\n\n\n\n\nWebpack 版本为 v4.46.0\nconst webpack = (options, callback) => &#123;\n\tconst webpackOptionsValidationErrors = validateSchema(\n\t\twebpackOptionsSchema,\n\t\toptions\n\t);\n\tif (webpackOptionsValidationErrors.length) &#123;\n\t\tthrow new WebpackOptionsValidationError(webpackOptionsValidationErrors);\n\t&#125;\n\tlet compiler;\n\tif (Array.isArray(options)) &#123;\n\t\tcompiler = new MultiCompiler(\n\t\t\tArray.from(options).map(options => webpack(options))\n\t\t);\n\t&#125; else if (typeof options === \"object\") &#123;\n\t\toptions = new WebpackOptionsDefaulter().process(options);\n\n\t\tcompiler = new Compiler(options.context);\n\t\tcompiler.options = options;\n\t\tnew NodeEnvironmentPlugin(&#123;\n\t\t\tinfrastructureLogging: options.infrastructureLogging\n\t\t&#125;).apply(compiler);\n\t\tif (options.plugins &amp;&amp; Array.isArray(options.plugins)) &#123;\n\t\t\tfor (const plugin of options.plugins) &#123;\n\t\t\t\tif (typeof plugin === \"function\") &#123;\n\t\t\t\t\tplugin.call(compiler, compiler);\n\t\t\t\t&#125; else &#123;\n\t\t\t\t\tplugin.apply(compiler);\n\t\t\t\t&#125;\n\t\t\t&#125;\n\t\t&#125;\n\t\tcompiler.hooks.environment.call();\n\t\tcompiler.hooks.afterEnvironment.call();\n\t\tcompiler.options = new WebpackOptionsApply().process(options, compiler);\n\t&#125; else &#123;\n\t\tthrow new Error(\"Invalid argument: options\");\n\t&#125;\n\tif (callback) &#123;\n\t\tif (typeof callback !== \"function\") &#123;\n\t\t\tthrow new Error(\"Invalid argument: callback\");\n\t\t&#125;\n\t\tif (\n\t\t\toptions.watch === true ||\n\t\t\t(Array.isArray(options) &amp;&amp; options.some(o => o.watch))\n\t\t) &#123;\n\t\t\tconst watchOptions = Array.isArray(options)\n\t\t\t\t? options.map(o => o.watchOptions || &#123;&#125;)\n\t\t\t\t: options.watchOptions || &#123;&#125;;\n\t\t\treturn compiler.watch(watchOptions, callback);\n\t\t&#125;\n\t\tcompiler.run(callback);\n\t&#125;\n\treturn compiler;\n&#125;;\n\n初始化参数\n\n\n\n\n\n\n\n\n\n从 配置文件、 配置对象、Shell参数 中读取，与 默认配置 结合得出最终的参数\n对应的核心代码为 options = new WebpackOptionsDefaulter().process(options) 且 class WebpackOptionsDefaulter extends OptionsDefaulter &#123;&#125;\n根据不同的合并规则进行 options 和 默认配置 的合并处理\n\nclass OptionsDefaulter &#123;\n\tprocess(options) &#123;\n\t\toptions = Object.assign(&#123;&#125;, options);\n\t\tfor (let name in this.defaults) &#123;\n\t\t\tswitch (this.config[name]) &#123;\n\t\t\t\t/**\n\t\t\t\t * If &#123;@link ConfigType&#125; doesn't specified and current value is `undefined`, then default value will be assigned\n\t\t\t\t */\n\t\t\t\tcase undefined:\n\t\t\t\t\tif (getProperty(options, name) === undefined) &#123;\n\t\t\t\t\t\tsetProperty(options, name, this.defaults[name]);\n\t\t\t\t\t&#125;\n\t\t\t\t\tbreak;\n\t\t\t\t/**\n\t\t\t\t * Assign result of &#123;@link CallConfigHandler&#125;\n\t\t\t\t */\n\t\t\t\tcase \"call\":\n\t\t\t\t\tsetProperty(\n\t\t\t\t\t\toptions,\n\t\t\t\t\t\tname,\n\t\t\t\t\t\tthis.defaults[name].call(this, getProperty(options, name), options)\n\t\t\t\t\t);\n\t\t\t\t\tbreak;\n\t\t\t\t/**\n\t\t\t\t * Assign result of &#123;@link MakeConfigHandler&#125;, if current value is `undefined`\n\t\t\t\t */\n\t\t\t\tcase \"make\":\n\t\t\t\t\tif (getProperty(options, name) === undefined) &#123;\n\t\t\t\t\t\tsetProperty(options, name, this.defaults[name].call(this, options));\n\t\t\t\t\t&#125;\n\t\t\t\t\tbreak;\n\t\t\t\t/**\n\t\t\t\t * Adding &#123;@link AppendConfigValues&#125; at the end of the current array\n\t\t\t\t */\n\t\t\t\tcase \"append\": &#123;\n\t\t\t\t\tlet oldValue = getProperty(options, name);\n\t\t\t\t\tif (!Array.isArray(oldValue)) &#123;\n\t\t\t\t\t\toldValue = [];\n\t\t\t\t\t&#125;\n\t\t\t\t\toldValue.push(...this.defaults[name]);\n\t\t\t\t\tsetProperty(options, name, oldValue);\n\t\t\t\t\tbreak;\n\t\t\t\t&#125;\n\t\t\t\tdefault:\n\t\t\t\t\tthrow new Error(\n\t\t\t\t\t\t\"OptionsDefaulter cannot process \" + this.config[name]\n\t\t\t\t\t);\n\t\t\t&#125;\n\t\t&#125;\n\t\treturn options;\n\t&#125;\n&#125;\n\n创建编译器对象\n\n\n\n\n\n\n\n\n\n通过上一步得到的 options.context 参数创建 Compiler 对象\n对应的核心代码为 compiler = new Compiler(options.context);\n\n初始化编译环境\n\n\n\n\n\n\n\n\n\n包括注入内置插件、注册各种模块工厂、初始化 RuleSet 集合、加载配置的插件等\n对应的核心代码为 plugin.apply(compiler) 和 compiler.options = new WebpackOptionsApply().process(options, compiler);\n\n开始编译\n\n\n\n\n\n\n\n\n\n执行 compiler 对象的 run 方法\n对应的核心代码为 compiler.run(callback);\n\nrun(callback) &#123;\n  if (this.running) return callback(new ConcurrentCompilationError());\n\n  const finalCallback = (err, stats) => &#123;\n    this.running = false;\n\n    if (err) &#123;\n      this.hooks.failed.call(err);\n    &#125;\n\n    if (callback !== undefined) return callback(err, stats);\n  &#125;;\n\n  const startTime = Date.now();\n\n  this.running = true;\n\n  const onCompiled = (err, compilation) => &#123;\n    if (err) return finalCallback(err);\n\n    if (this.hooks.shouldEmit.call(compilation) === false) &#123;\n      const stats = new Stats(compilation);\n      stats.startTime = startTime;\n      stats.endTime = Date.now();\n      this.hooks.done.callAsync(stats, err => &#123;\n        if (err) return finalCallback(err);\n        return finalCallback(null, stats);\n      &#125;);\n      return;\n    &#125;\n\n    this.emitAssets(compilation, err => &#123;\n      if (err) return finalCallback(err);\n\n      if (compilation.hooks.needAdditionalPass.call()) &#123;\n        compilation.needAdditionalPass = true;\n\n        const stats = new Stats(compilation);\n        stats.startTime = startTime;\n        stats.endTime = Date.now();\n        this.hooks.done.callAsync(stats, err => &#123;\n          if (err) return finalCallback(err);\n\n          this.hooks.additionalPass.callAsync(err => &#123;\n            if (err) return finalCallback(err);\n            this.compile(onCompiled);\n          &#125;);\n        &#125;);\n        return;\n      &#125;\n\n      this.emitRecords(err => &#123;\n        if (err) return finalCallback(err);\n\n        const stats = new Stats(compilation);\n        stats.startTime = startTime;\n        stats.endTime = Date.now();\n        this.hooks.done.callAsync(stats, err => &#123;\n          if (err) return finalCallback(err);\n          return finalCallback(null, stats);\n        &#125;);\n      &#125;);\n    &#125;);\n  &#125;;\n\n  this.hooks.beforeRun.callAsync(this, err => &#123;\n    if (err) return finalCallback(err);\n\n    this.hooks.run.callAsync(this, err => &#123;\n      if (err) return finalCallback(err);\n\n      this.readRecords(err => &#123;\n        if (err) return finalCallback(err);\n\n        this.compile(onCompiled);\n      &#125;);\n    &#125;);\n  &#125;);\n&#125;\n\n\n\n\n\n\n\n\n\n\nthis.compile(onCompiled) 是整个编译过程启动的入口一个 compilation 对象表现了当前的模块资源、编译生成资源、变化的文件、以及被跟踪依赖的状态信息，代表了一次资源的构建。\ncompile(callback) &#123;\n  const params = this.newCompilationParams();\n  this.hooks.beforeCompile.callAsync(params, err => &#123;\n    if (err) return callback(err);\n\n    this.hooks.compile.call(params);\n\n    const compilation = this.newCompilation(params);\n\n    this.hooks.make.callAsync(compilation, err => &#123;\n      if (err) return callback(err);\n\n      compilation.finish(err => &#123;\n        if (err) return callback(err);\n\n        compilation.seal(err => &#123;\n          if (err) return callback(err);\n\n          this.hooks.afterCompile.callAsync(compilation, err => &#123;\n            if (err) return callback(err);\n\n            return callback(null, compilation);\n          &#125;);\n        &#125;);\n      &#125;);\n    &#125;);\n  &#125;);\n&#125;\n\nnewCompilationParams() &#123;\n  const params = &#123;\n    normalModuleFactory: this.createNormalModuleFactory(),\n    contextModuleFactory: this.createContextModuleFactory(),\n    compilationDependencies: new Set()\n  &#125;;\n  return params;\n&#125;\n\nnewCompilation(params) &#123;\n  const compilation = this.createCompilation();\n  compilation.fileTimestamps = this.fileTimestamps;\n  compilation.contextTimestamps = this.contextTimestamps;\n  compilation.name = this.name;\n  compilation.records = this.records;\n  compilation.compilationDependencies = params.compilationDependencies;\n  this.hooks.thisCompilation.call(compilation, params);\n  this.hooks.compilation.call(compilation, params);\n  return compilation;\n&#125;\n\n总结\n\n\n\n\n\n\n\n\n\n将 process.args + webpack.config.js 合并成用户配置\n调用 validateSchema 校验配置\n调用 new WebpackOptionsDefaulter().process(options) 合并出最终配置\n创建 compiler 对象\n遍历用户定义的 plugins 集合，执行插件的 apply 方法\n调用 new WebpackOptionsApply().process(options, compiler) 方法，加载各种内置插件\n主要逻辑集中在 WebpackOptionsApply 类，webpack 内置了数百个插件，这些插件并不需要我们手动配置，WebpackOptionsApply 会在初始化阶段根据配置内容动态注入对应的插件，比如包括：\n\n注入 EntryOptionPlugin 插件，处理 entry 配置\n根据 devtool 值判断后续用那个插件处理 sourcemap，可选值：EvalSourceMapDevToolPlugin、SourceMapDevToolPlugin、EvalDevToolModulePlugin\n根据 optimization.$&#123;key&#125; 配置（$&#123;key&#125; - removeAvailableModules、removeEmptyChunks、mergeDuplicateChunks、flagIncludedChunks、sideEffects、providedExports、usedExports、concatenateModules、splitChunks、runtimeChunk、noEmitOnErrors、checkWasmTypes）自动加载对应的插件\n注入 RuntimePlugin ，用于根据代码内容动态注入 webpack 运行时\n\n\ncompiler.run 实际调用 compiler.compile 函数，实际调用 this.hooks.make.callAsync，从而触发 EntryPlugin 的 compiler.hooks.make.tapAsync 回调，在回调中执行 compilation.addEntry 函数；compilation.addEntry 函数内部经过一坨与主流程无关的 hook 之后，再调用 handleModuleCreate 函数，正式开始构建内容\n\n\n参考[万字总结] 一文吃透 Webpack 核心原理[源码解读] Webpack 插件架构深度讲解\n","slug":"webpack-stage-init","date":"2022-02-19T22:52:44.000Z","categories_index":"","tags_index":"Webpack","author_index":"Matrix"},{"id":"e8dd10177843eb97f466f57c44ebeb35","title":"React 合成事件系统","content":"\nJSX 事件绑定 -&gt; Fiberclass Index extends React.Component&#123;\n    handerClick= (value) => console.log(value)\n    render()&#123;\n        return &lt;div>\n            &lt;button onClick=&#123; this.handerClick &#125; > 按钮点击 &lt;/button>\n        &lt;/div>\n    &#125;\n&#125;\n\n经过 babel 转换成 React.createElement 形式最终转成 fiber 对象形式如下fiber 对象上的 memoizedProps 和 pendingProps 保存了我们的事件。\n什么是 React 合成事件？class Index extends React.Component&#123;\n    componentDidMount()&#123;\n        console.log(this)\n    &#125;\n    handerClick= (value) => console.log(value)\n    handerChange=(value) => console.log(value)\n    render()&#123;\n        return &lt;div>\n            &lt;button onClick=&#123;this.handerClick&#125; > 按钮点击 &lt;/button>\n            &lt;input placeholder=\"请输入内容\" onChange=&#123;this.handerChange&#125;  />\n        &lt;/div>\n    &#125;\n&#125;\n\n我们先看一下 input dom 元素上绑定的事件然后我们看一下 document 上绑定的事件我们发现，我们给 &lt;input&gt; 绑定的 onChange，并没有直接绑定在 input 上，而是统一绑定在了 document 上，然后我们 onChange 被处理成很多事件监听器，比如 blur , change , input , keydown , keyup 等。\n\n\n\n\n\n\n\n\n\n综上我们可以得出结论：① 我们在 jsx 中绑定的事件(handerClick，handerChange),根本就没有注册到真实的 dom 上。是绑定在 document 上统一管理的。② 真实的 dom 上的 click 事件被单独处理,已经被 react 底层替换成空函数。③ 我们在 react 绑定的事件,比如 onChange，在 document 上，可能有多个事件与之对应。④ react 并不是一开始，把所有的事件都绑定在 document 上，而是采取了一种按需绑定，比如发现了 onClick 事件,再去绑定 document click 事件。\n事件合成的插件机制必要概念①namesToPlugins - 事件名 -&gt; 事件模块插件的映射\nconst namesToPlugins = &#123;\n  SimpleEventPlugin,\n  EnterLeaveEventPlugin,\n  ChangeEventPlugin,\n  SelectEventPlugin,\n  BeforeInputEventPlugin,\n&#125;\n\n②plugins - 注册的所有插件列表,初始化为空\nconst plugins = [LegacySimpleEventPlugin, LegacyEnterLeaveEventPlugin, ...];\n\n③registrationNameModules - 合成的事件 -&gt; 事件插件的映射\n&#123;\n    onBlur: SimpleEventPlugin,\n    onClick: SimpleEventPlugin,\n    onClickCapture: SimpleEventPlugin,\n    onChange: ChangeEventPlugin,\n    onChangeCapture: ChangeEventPlugin,\n    onMouseEnter: EnterLeaveEventPlugin,\n    onMouseLeave: EnterLeaveEventPlugin,\n    ...\n&#125;\n\n④ 事件插件 - 以 SimpleEventPlugin 为例\nconst SimpleEventPlugin = &#123;\n    eventTypes:&#123;\n        'click':&#123; /* 处理点击事件  */\n            phasedRegistrationNames:&#123;\n                bubbled: 'onClick',       // 对应事件冒泡阶段 - onClick\n                captured:'onClickCapture' // 对应事件捕获阶段 - onClickCapture\n            &#125;,\n            dependencies: ['click'], // 事件依赖\n            ...\n        &#125;,\n        'blur':&#123; /* 处理失去焦点事件 */ &#125;,\n        ...\n    &#125;\n    extractEvents:function(topLevelType,targetInst,nativeEvent,nativeEventTarget)&#123; /* eventTypes 里面的事件对应的统一事件处理函数，接下来会重点讲到 */ &#125;\n&#125;\n\n即：事件插件是一个对象，有两个属性，extractEvents 作为事件统一处理函数；eventTypes 对象保存了原生事件名和对应的配置项 dispatchConfig 的映射关系。\n由于 React v16 的事件是统一绑定在 document 上的，React 用独特的事件名称比如 onClick 和 onClickCapture，来说明我们给绑定的函数到底是在冒泡事件阶段，还是捕获事件阶段执行。\n⑤ registrationNameDependencies - 记录合成事件 -&gt; 原生事件的映射关系\n比如 onClick 和原生事件 click 对应关系比如 onChange 对应 change , input , keydown , keyup 事件\n&#123;\n    onBlur: ['blur'],\n    onClick: ['click'],\n    onClickCapture: ['click'],\n    onChange: ['blur', 'change', 'click', 'focus', 'input', 'keydown', 'keyup', 'selectionchange'],\n    onMouseEnter: ['mouseout', 'mouseover'],\n    onMouseLeave: ['mouseout', 'mouseover'],\n    ...\n&#125;\n\n事件初始化对于事件合成，v16.13.1 版本 react 采用了初始化注册方式。\n/* 第一步：注册事件：react-dom/src/client/ReactDOMClientInjection.js  */\ninjectEventPluginsByName(&#123;\n    SimpleEventPlugin: SimpleEventPlugin,\n    EnterLeaveEventPlugin: EnterLeaveEventPlugin,\n    ChangeEventPlugin: ChangeEventPlugin,\n    SelectEventPlugin: SelectEventPlugin,\n    BeforeInputEventPlugin: BeforeInputEventPlugin,\n&#125;);\n\n\n/* 注册事件插件 */\nexport function injectEventPluginsByName(injectedNamesToPlugins)&#123;\n     for (const pluginName in injectedNamesToPlugins) &#123;\n         namesToPlugins[pluginName] = injectedNamesToPlugins[pluginName]\n     &#125;\n     recomputePluginOrdering()\n&#125;\n\ninjectEventPluginsByName 做的事情很简单，形成上述的 namesToPlugins，然后执行 recomputePluginOrdering\nconst eventPluginOrder = [ 'SimpleEventPlugin' , 'EnterLeaveEventPlugin','ChangeEventPlugin','SelectEventPlugin' , 'BeforeInputEventPlugin' ]\n\nfunction recomputePluginOrdering()&#123;\n    for (const pluginName in namesToPlugins) &#123;\n        /* 找到对应的事件处理插件，比如 SimpleEventPlugin  */\n        const pluginModule = namesToPlugins[pluginName];\n        const pluginIndex = eventPluginOrder.indexOf(pluginName);\n        /* 填充 plugins 数组  */\n        plugins[pluginIndex] = pluginModule;\n        const publishedEvents = pluginModule.eventTypes;\n    for (const eventName in publishedEvents) &#123;\n       // publishedEvents[eventName] -> eventConfig , pluginModule -> 事件插件 ， eventName -> 事件名称\n        publishEventForPlugin(publishedEvents[eventName],pluginModule,eventName,)\n    &#125;\n    &#125;\n&#125;\n\nrecomputePluginOrdering 作用很明确了，形成上面说的那个 plugins 数组。然后就是重点的函数 publishEventForPlugin\n/*\n  dispatchConfig -> 原生事件对应配置项 &#123; phasedRegistrationNames :&#123;  冒泡 捕获  &#125; ，   &#125;\n  pluginModule -> 事件插件 比如SimpleEventPlugin\n  eventName -> 原生事件名称。\n*/\nfunction publishEventForPlugin (dispatchConfig,pluginModule,eventName)&#123;\n    eventNameDispatchConfigs[eventName] = dispatchConfig;\n    /* 事件 */\n    const phasedRegistrationNames = dispatchConfig.phasedRegistrationNames;\n    if (phasedRegistrationNames) &#123;\n    for (const phaseName in phasedRegistrationNames) &#123;\n        if (phasedRegistrationNames.hasOwnProperty(phaseName)) &#123;\n            // phasedRegistrationName React事件名 比如 onClick / onClickCapture\n            const phasedRegistrationName = phasedRegistrationNames[phaseName];\n            // 填充形成 registrationNameModules React 合成事件 -> React 处理事件插件映射关系\n            registrationNameModules[phasedRegistrationName] = pluginModule;\n            // 填充形成 registrationNameDependencies React 合成事件 -> 原生事件 映射关系\n            registrationNameDependencies[phasedRegistrationName] = pluginModule.eventTypes[eventName].dependencies;\n        &#125;\n    &#125;\n    return true;\n    &#125;\n&#125;\n\n事件合成总结初始化事件合成阶段主要做了：形成了上述的几个重要对象，构建初始化 React 合成事件和原生事件的对应关系，合成事件和对应的事件处理插件关系。\n事件绑定流程diffProperties 处理 React 合成事件\nReact 在调合子节点后，进入 diff 阶段，如果判断是 HostComponent(dom 元素)类型的 fiber，会用 diff props 函数 diffProperties 单独处理\n// react-dom/src/client/ReactDOMComponent.js\nfunction diffProperties()&#123;\n    /* 判断当前的 propKey 是不是 React合成事件 */\n    if(registrationNameModules.hasOwnProperty(propKey))&#123;\n         /* 这里多个函数简化了，如果是合成事件， 传入成事件名称 onClick ，向document注册事件  */\n         legacyListenToEvent(registrationName, document）;\n    &#125;\n&#125;\n\ndiffProperties 函数在 diff props 如果发现是合成事件(onClick) 就会调用 legacyListenToEvent 函数。注册事件监听器\nlegacyListenToEvent 注册事件监听器//  registrationName -> onClick 事件\n//  mountAt -> document or container\nfunction legacyListenToEvent(registrationName，mountAt)&#123;\n   const dependencies = registrationNameDependencies[registrationName]; // 根据 onClick 获取  onClick 依赖的事件数组 [ 'click' ]。\n    for (let i = 0; i &lt; dependencies.length; i++) &#123;\n    const dependency = dependencies[i];\n    //这个经过多个函数简化，如果是 click 基础事件，会走 legacyTrapBubbledEvent ,而且都是按照冒泡处理\n     legacyTrapBubbledEvent(dependency, mountAt);\n  &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n注意 ⚠️：在 legacyListenToEvent 函数中，先找到 React 合成事件对应的原生事件集合，比如 onClick -&gt; [&#39;click&#39;] , onChange -&gt; [blur , change , input , keydown , keyup]，然后遍历依赖项的数组，绑定事件，这就解释了，为什么我们在刚开始的 demo 中，只给元素绑定了一个 onChange 事件，结果在 document 上出现很多事件监听器的原因，就是在这个函数上处理的\nlegacyTrapBubbledEvent 就是执行将绑定真正的 dom 事件的函数 legacyTrapBubbledEvent(冒泡处理)。\nfunction legacyTrapBubbledEvent(topLevelType,element)&#123;\n   addTrappedEventListener(element,topLevelType,PLUGIN_EVENT_SYSTEM,false)\n&#125;\n\n\n\n\n\n\n\n\n\n\n注意 ⚠️：React 是采用事件绑定，React 对于 click 等基础事件，会默认按照事件 冒泡阶段 的事件处理，不过这也不绝对的，比如一些事件的处理，有些特殊的事件，如 scroll、focus、blur 是按照 事件捕获 处理的。\ncase TOP_SCROLL: &#123;                                // scroll 事件\n    legacyTrapCapturedEvent(TOP_SCROLL, mountAt); // legacyTrapCapturedEvent 事件捕获处理。\n    break;\n&#125;\ncase TOP_FOCUS: // focus 事件\ncase TOP_BLUR:  // blur 事件\nlegacyTrapCapturedEvent(TOP_FOCUS, mountAt);\nlegacyTrapCapturedEvent(TOP_BLUR, mountAt);\nbreak;\n\n绑定 dispatchEvent，进行事件监听如上述的 scroll 事件，focus 事件 ，blur 事件等，是默认按照事件捕获逻辑处理。接下来就是最重要关键的一步。React 是如何绑定事件到 document？ 事件处理函数函数又是什么？问题都指向了上述的 addTrappedEventListener，让我们来揭开它的面纱。\n/*\n  targetContainer -> document\n  topLevelType ->  click\n  capture = false\n*/\nfunction addTrappedEventListener(targetContainer,topLevelType,eventSystemFlags,capture)&#123;\n   const listener = dispatchEvent.bind(null,topLevelType,eventSystemFlags,targetContainer)\n   if(capture)&#123;\n       // 事件捕获阶段处理函数。\n   &#125;else&#123;\n       /* TODO: 重要, 这里进行真正的事件绑定。*/\n      targetContainer.addEventListener(topLevelType,listener,false) // document.addEventListener('click',listener,false)\n   &#125;\n&#125;\n\n这个函数内容虽然不多，但是却非常重要,首先绑定我们的事件统一处理函数 dispatchEvent，绑定几个默认参数，事件类型 topLevelType demo 中的 click ，还有绑定的容器 doucment。然后真正的事件绑定,添加事件监听器 addEventListener， 事件绑定阶段完毕。\n事件触发流程extractEvents 形成事件对象 event 和 事件处理函数队列\nconst  SimpleEventPlugin = &#123;\n    extractEvents:function(topLevelType,targetInst,nativeEvent,nativeEventTarget)&#123;\n        const dispatchConfig = topLevelEventsToDispatchConfig.get(topLevelType);\n        if (!dispatchConfig) &#123;\n            return null;\n        &#125;\n        switch(topLevelType)&#123;\n            default:\n            EventConstructor = SyntheticEvent;\n            break;\n        &#125;\n        /* 产生事件源对象 */\n        const event = EventConstructor.getPooled(dispatchConfig,targetInst,nativeEvent,nativeEventTarget)\n        const phasedRegistrationNames = event.dispatchConfig.phasedRegistrationNames;\n        const dispatchListeners = [];\n        const &#123;bubbled, captured&#125; = phasedRegistrationNames; /* onClick / onClickCapture */\n        const dispatchInstances = [];\n        /* 从事件源开始逐渐向上，查找dom元素类型HostComponent对应的fiber ，收集上面的React合成事件，onClick / onClickCapture  */\n         while (instance !== null) &#123;\n              const &#123;stateNode, tag&#125; = instance;\n              if (tag === HostComponent &amp;&amp; stateNode !== null) &#123; /* DOM 元素 */\n                   const currentTarget = stateNode;\n                   if (captured !== null) &#123; /* 事件捕获 */\n                        /* 在事件捕获阶段,真正的事件处理函数 */\n                        const captureListener = getListener(instance, captured);\n                        if (captureListener != null) &#123;\n                        /* 对应发生在事件捕获阶段的处理函数，逻辑是将执行函数unshift添加到队列的最前面 */\n                            dispatchListeners.unshift(captureListener);\n                            dispatchInstances.unshift(instance);\n                            dispatchCurrentTargets.unshift(currentTarget);\n                        &#125;\n                    &#125;\n                    if (bubbled !== null) &#123; /* 事件冒泡 */\n                        /* 事件冒泡阶段，真正的事件处理函数，逻辑是将执行函数push到执行队列的最后面 */\n                        const bubbleListener = getListener(instance, bubbled);\n                        if (bubbleListener != null) &#123;\n                            dispatchListeners.push(bubbleListener);\n                            dispatchInstances.push(instance);\n                            dispatchCurrentTargets.push(currentTarget);\n                        &#125;\n                    &#125;\n              &#125;\n              instance = instance.return;\n         &#125;\n          if (dispatchListeners.length > 0) &#123;\n              /* 将函数执行队列，挂到事件对象event上 */\n            event._dispatchListeners = dispatchListeners;\n            event._dispatchInstances = dispatchInstances;\n            event._dispatchCurrentTargets = dispatchCurrentTargets;\n         &#125;\n        return event\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n事件插件系统的核心 extractEvents 主要做的事是:\n① 首先形成 React 事件独有的合成事件源对象，这个对象，保存了整个事件的信息。将作为参数传递给真正的事件处理函数(handerClick)。② 然后声明事件执行队列 ，按照冒泡和捕获逻辑，从事件源开始逐渐向上，查找 dom 元素类型 HostComponent 对应的 fiber ，收集上面的 React 合成事件，例如 onClick &#x2F; onClickCapture ，对于冒泡阶段的事件(onClick)，将 push 到执行队列后面 ， 对于捕获阶段的事件(onClickCapture)，将 unShift 到执行队列的前面。③ 最后将事件执行队列，保存到 React 事件源对象上。等待执行。\n\n\n\n\n\n\n\n\n\n举个 🌰\nrender()&#123;\n   return &lt;div onClick=&#123; this.handerClick2 &#125; onClickCapture=&#123; this.handerClick3 &#125;>\n       &lt;button onClick=&#123; this.handerClick &#125;  onClickCapture=&#123; this.handerClick1 &#125;>点击&lt;/button>\n   &lt;/div>\n&#125;\n\n\n事件触发React 的事件源对象 SyntheticEvent\nfunction SyntheticEvent( dispatchConfig,targetInst,nativeEvent,nativeEventTarget)&#123;\n  this.dispatchConfig = dispatchConfig;\n  this._targetInst = targetInst;\n  this.nativeEvent = nativeEvent;\n  this._dispatchListeners = null;\n  this._dispatchInstances = null;\n  this._dispatchCurrentTargets = null;\n  this.isPropagationStopped = () => false; /* 初始化，返回为false  */\n\n&#125;\nSyntheticEvent.prototype=&#123;\n    stopPropagation()&#123; this.isPropagationStopped = () => true;  &#125;, /* React单独处理，阻止事件冒泡函数 */\n    preventDefault()&#123; &#125;,  /* React单独处理，阻止事件捕获函数  */\n    ...\n&#125;\n\n事件执行队列 和 事件源对象 都形成了，接下来就是最后一步事件触发了。上面大家有没有注意到一个函数 runEventsInBatch，所有事件绑定函数，就是在这里触发的\nfunction runEventsInBatch()&#123;\n    const dispatchListeners = event._dispatchListeners;\n    const dispatchInstances = event._dispatchInstances;\n    if (Array.isArray(dispatchListeners)) &#123;\n    for (let i = 0; i &lt; dispatchListeners.length; i++) &#123;\n      if (event.isPropagationStopped()) &#123; /* 判断是否已经阻止事件冒泡 */\n        break;\n      &#125;\n\n      dispatchListeners[i](event)\n    &#125;\n  &#125;\n  /* 执行完函数，置空两字段 */\n  event._dispatchListeners = null;\n  event._dispatchInstances = null;\n&#125;\n\n\n\n\n\n\n\n\n\n\n注意 ⚠️：React 对于 阻止冒泡，就是通过 isPropagationStopped 判断是否已经阻止事件冒泡。如果我们在事件函数执行队列中，某一会函数中，调用 e.stopPropagation() 就会赋值给 isPropagationStopped = () =&gt; true，当再执行 e.isPropagationStopped() 就会返回 true ,接下来事件处理函数，就不会执行了。同理，对于 阻止浏览器默认行为 也必须使用 e.preventDefault() 即\n// 以下逻辑不能阻止浏览器默认行为。\nhanderClick() &#123;\n   return false\n&#125;\n// 应该改为\nhanderClick(e) &#123;\n   e.preventDefault()\n&#125;\n其他概念-事件池 handerClick = (e) => &#123;\n    console.log(e.target) // button\n    setTimeout(()=>&#123;\n        console.log(e.target) // null\n    &#125;,0)\n&#125;\n\n对于一次点击事件的处理函数，在正常的函数执行上下文中打印 e.target 就指向了 dom 元素，但是在 setTimeout 中打印却是 null，如果这不是 React 事件系统，两次打印的应该是一样的，但是为什么两次打印不一样呢？\n\n\n\n\n\n\n\n\n\n因为在 React 采取了一个事件池的概念，每次我们用的事件源对象，在事件函数执行之后，可以通过 releaseTopLevelCallbackBookKeeping 等方法将事件源对象释放到事件池中，这样的好处每次我们不必再创建事件源对象，可以从事件池中取出一个事件源对象进行复用，在事件处理函数执行完毕后,会释放事件源到事件池中，清空属性，这就是 setTimeout 中打印为什么是 null 的原因了。\n关于 React v17 版本的事件系统React v17 整体改动不是很大，但是事件系统的改动却不小，首先上述的很多执行函数，在 v17 版本不复存在了\n事件代理不再绑定至 document，而是 root事件统一绑定 container 上，ReactDOM.render(app， container);而不是 document 上，这样好处是有利于 微前端 的，微前端 一个前端系统中可能有多个应用，如果继续采取全部绑定在 document 上，那么可能多应用下会出现问题。\n\n对齐原生浏览器事件React 17 中终于支持了 原生捕获事件 的支持， 对齐了浏览器原生标准。同时 onScroll 事件不再进行事件冒泡(解决 v16 问题：当滚动子元素时，父元素上的 onScroll 回调会触发)。onFocus 和 onBlur 使用原生 focusin， focusout 合成。\n取消事件池React 17 取消事件池复用，也就解决了上述在 setTimeout 打印，找不到 e.target 的问题。\n参考「react 进阶」一文吃透 react 事件系统原理React v17.0 的 6 大变化\n","slug":"react-event-system","date":"2022-02-16T22:12:01.000Z","categories_index":"","tags_index":"React","author_index":"Matrix"},{"id":"f8393fb18aa0424e4c73686abd0807ce","title":"Source Map","content":"为什么需要 Source map？这个要从源码转换讲起，JavaScript 脚本正变得越来越复杂。大部分源码（尤其是各种函数库和框架）都要经过转换，才能投入生产环境。\n\n\n\n\n\n\n\n\n\n常见的源码转换，主要是以下三种情况：\n（1）压缩，减小体积。比如 jQuery 1.9 的源码，压缩前是 252KB，压缩后是 32KB。（2）多个文件合并，减少 HTTP 请求数。（3）其他语言编译成 JavaScript。最常见的例子就是 CoffeeScript。\n这三种情况，都使得实际运行的代码不同于开发代码，除错（debug）变得困难重重。通常，JavaScript 的解释器会告诉你，第几行第几列代码出错。但是，这对于转换后的代码毫无用处。举例来说，jQuery 1.9 压缩后只有 3 行，每行 3 万个字符，所有内部变量都改了名字。你看着报错信息，感到毫无头绪，根本不知道它所对应的原始位置。\n这就是 Source map 想要解决的问题。\n什么是 Source map？简单说，Source map 就是一个信息文件，里面储存着位置信息。也就是说，转换后的代码的每一个位置，所对应的转换前的位置。\n有了它，出错的时候，除错工具将直接显示原始代码，而不是转换后的代码。这无疑给开发者带来了很大方便。\n\n如何启用 Source map？正如前文所提到的，只要在转换后的代码尾部，加上一行就可以了。\n　//@ sourceMappingURL=/path/to/file.js.map\n\nmap 文件可以放在网络上，也可以放在本地文件系统。那这里就不得不提 Webpack Devtool 配置。\nSource map 字段解读&#123;\n  \"version\": 3,\n  \"file\": \"main.js\",\n  \"sources\": [\n    \"../src/main.js\"\n  ],\n  \"sourcesContent\": [\n    \"throw new Error('error 1');\\n\"\n  ],\n  \"names\": [\n    \"Error\"\n  ],\n  \"mappings\": \";;AAAA,MAAM,IAAIA,KAAJ,CAAU,SAAV,CAAN\"\n&#125;\n\n\n\n\n\n\n\n\n\n\nversion： sourceMap 版本，目前的版本是 3。file：转换后的文件名。sources：转换前的文件。该项是一个数组，表示可能存在多个文件合并。sourcesContent：source 中文件对应的源代码，是个数组names：转换前的所有变量名和属性名。mappings：记录位置信息的字符串。\n\n关键就是 map 文件的 mappings 属性。这是一个很长的字符串，它分成三层\n\n第一层是行对应，以分号 ; 表示，每个分号对应转换后源码的一行。所以，第一个分号前的内容，就对应源码的第一行，以此类推。\n第二层是位置对应，以逗号 ,表示，每个逗号对应转换后源码的一个位置。所以，第一个逗号前的内容，就对应该行源码的第一个位置，以此类推。\n第三层是位置转换，以 VLQ 编码表示，代表该位置对应的转换前的源码位置。\n\n\nWebpack Devtool 配置\n\n\n模式\n解释\n缺点\n\n\n\neval\n每个 module 会封装到 eval 里包裹起来执行，并且会在末尾追加注释 &#x2F;&#x2F;@ sourceURL\n映射到转换后的代码，而不是映射到原始代码\n\n\nsource-map\n整个 source map 作为一个单独的文件生成。它为 bundle 添加了一个引用注释，以便开发工具知道在哪里可以找到它\n不建议生产环境（应该将你的服务器配置为，不允许普通用户访问 source map 文件）\n\n\nhidden-source-map\n与 source-map 相同，但不会为 bundle 添加引用注释\n不建议生产环境（不应将 source map 文件部署到 web 服务器。而是只将其用于错误报告工具）\n\n\nnosources-source-map\n创建的 source map 不包含 sourcesContent(源代码内容)\n可将 source map 文件部署到 web 服务器，但仍然会暴露反编译后的文件名和结构，但它不会暴露原始代码\n\n\ninline-source-map\nsource map 转换为 DataUrl 后添加到 bundle 中\nbundle 体积巨增\n\n\ncheap-source-map\n没有列映射(column mapping)的 source map\n忽略 loader source map\n\n\ninline-cheap-source-map\n类似 cheap-source-map，但是 source map 转换为 DataUrl 后添加到 bundle 中\nbundle 体积增大\n\n\ncheap-module-source-map\n没有列映射(column mapping)的 source map，将 loader source map 简化为每行一个映射(mapping)\n–\n\n\ninline-cheap-module-source-map\n类似 cheap-module-source-map，但是 source map 转换为 DataUrl 添加到 bundle 中\n–\n\n\nWebpack Devtool 配置控制是否生成，以及如何生成 source map\n参考Webpack 官方文档 - Devtool 配置聊个 5 毛钱的 Source Map如何在正式环境无害的使用 sourceMap？JavaScript Source Map 详解\n","slug":"sourcemap","date":"2022-02-16T18:13:27.000Z","categories_index":"","tags_index":"Webpack","author_index":"Matrix"},{"id":"1be78549da2d3dbc703ef7208cb57948","title":"Chrome 80+","content":"Chrome 80 策略更新Chrome 80 稳定版（版本号 v80.0.3987.87）已正式面向 Windows、macOS、Linux、Android 和 iOS 全平台推送\n混合内容强制 HTTPS混合内容是指 https 页面下有非 https 资源时，浏览器的加载策略。\n在 Chrome 80 中，如果你的页面开启了 https，同时你在页面中请求了 http 的音频和视频资源，这些资源将将自动升级为 https ，并且默认情况下，如果它们无法通过 https 加载，Chrome 将阻止它们。这样就会造成一些未支持 https 协议的资源加载失败。\n如果你想临时访问这些资源，你可以通过更改下面的浏览器设置来访问：\n\n\n\n\n\n\n\n\n\n\n单击地址栏上的锁定图标并选择 “站点设置”\n\n将 “隐私设置和安全性” 中的 “不安全内容” 选择为 “允许”\n\n你还可以通过设置 StricterMixedContentTreatmentEnabled 策略来控制这些变化：\n\n此策略控制浏览器中混合内容（HTTPS 站点中的 HTTP 内容）的处理方式。如果该政策设置为 true 或未设置，则音频和视频混合内容将自动升级为 HTTPS（即，URL 将被重写为 HTTPS，如果资源不能通过 HTTPS 获得，则不会进行回退），并且将显示“不安全”警告在网址列中显示图片混合内容。如果该策略设置为 false，则将禁用音频和视频的自动升级，并且不会显示图像警告。该策略不影响音频，视频和图像以外的其他类型的混合内容。\n但是以上策略是一个临时策略，将在 Chrome 84 中删除。更合理的方式是你需要推动全站资源开启 HTTPS。Chrome 也是推荐大家这么做的\n\n\n\n强推 SameSite CookieSameSite 是 Chrome 51 版本为浏览器的 Cookie 新增的了一个属性， SameSite 阻止浏览器将此 Cookie 与跨站点请求一起发送。其主要目标是降低跨源信息泄漏的风险。同时也在一定程度上阻止了 CSRF（Cross-site request forgery 跨站请求伪造）\nCookie 往往用来存储用户的身份信息，恶意网站可以设法伪造带有正确 Cookie 的 HTTP 请求，这就是 CSRF 攻击。\n\n\n\n\n\n\n\n\n\nSameSite 可以避免跨站请求发送 Cookie，有以下三个属性：\n\nStrictStrict 是最严格的防护，将阻止浏览器在所有跨站点浏览上下文中将 Cookie 发送到目标站点，即使在遵循常规链接时也是如此。因此这种设置可以阻止所有 CSRF 攻击。然而，它的用户友好性太差，即使是普通的 GET 请求它也不允许通过。例如，对于一个普通的站点，这意味着如果一个已经登录的用户跟踪一个发布在公司讨论论坛或电子邮件上的网站链接，这个站点将不会收到 Cookie ，用户访问该站点还需要重新登陆。不过，具有交易业务的网站很可能不希望从外站链接到任何交易页面，因此这种场景最适合使用 strict 标志。\nLax对于允许用户从外部链接到达本站并使用已有会话的网站站，默认的 Lax 值在安全性和可用性之间提供了合理的平衡。Lax 属性只会在使用危险 HTTP 方法发送跨域 Cookie 的时候进行阻止，例如 POST 方式。例如，一个用户在 A 站点 点击了一个 B 站点（GET 请求），而假如 B 站点 使用了 Samesite-cookies&#x3D;Lax，那么用户可以正常登录 B 站点。相对地，如果用户在 A 站点提交了一个表单到 B 站点（POST 请求），那么用户的请求将被阻止，因为浏览器不允许使用 POST 方式将 Cookie 从 A 域发送到Ｂ域。\nNone浏览器会在同站请求、跨站请求下继续发送 Cookies，不区分大小写。\n\n以上更新可能对以下功能造成影响：\n\n跨域名登陆失效\njsonp 获取数据失效\niframe 嵌套的页面打不开或异常\n部分客户端未改造导致各种数据获取异常\n\n正式支持 JavaScript Optional chaining &amp; Nullish coalescingJavaScript Optional chaining// 对象式写法\n// 通常写法\nconst nestedProp = obj.first &amp;&amp; obj.first.second;\n// 支持JavaScript Optional chaining后我们可以不用再做无谓的判断逻辑了\nconst nestedProp = obj.first?.second;\n\n// 数组式写法\n// 通常写法\nconst firstEl = arr &amp;&amp; Array.isArray(arr) &amp;&amp; arr[0];\n// 支持JavaScript Optional chaining后\nconst firstEl = arr?.[0];\n\n// 函数式写法\n// 通常写法\nconst result = someInterface.customMethod &amp;&amp; someInterface.customMethod();\n// 支持JavaScript Optional chaining后\nconst result = someInterface.customMethod?.();\n\n\n\n\n\n\n\n\n\n\n注：如果在开发的时候，需要兼容一些旧版本的浏览器的话可以考虑引入 @babel/plugin-proposal-optional-chaining 插件\nNullish coalescing/***************** Example 1 *******************/\nconst foo;\n\n//  在下面代码执行完之后foo还是undefined，并没有被赋值，bar的结果一定会是'hello'\nconst bar = foo || 'Hello!';\n\n/***************** Example 2 *******************/\n\nconst num = 0;\nconst txt = '';\n\nconst qty = num || 42;\nconst team = txt || 'AIPE-FE';\nconsole.log(qty);  // 42 and not 0\nconsole.log(team); // \"AIPE-FE\" and not ''\n\n/***************** Example 3 *******************/\n\nlet txt = '';\n\nconst team = txt || 'AIPE-FE';\nconsole.log(team); // 'AIPE-FE'\n\nlet result = txt ?? 'AIPE-FE';\nconsole.log(result); // '' (这个时候txt就不再是''了，而是被赋值成'AIPE-FE');\n\n/***************** Example 4 *******************/\nconst nullValue = null;\nconst emptyText = '';\nconst someNumber = 42;\n\nconst valA = nullValue ?? 'default for A';\nconst valB = emptyText ?? 'default for B';\nconst valC = someNumber ?? 0;\n\nconsole.log(valA); // 'default for A'\nconsole.log(valB); // '' (as the empty string is not null or undefined)\nconsole.log(valC); // 42\n\n\n\n\n\n\n\n\n\n\n注：如果在开发的时候，需要兼容一些旧版本的浏览器的话可以考虑引入 @babel/plugin-proposal-nullish-coalescing-operator 插件\nFavicon 图标支持 SVG 格式这个升级点就不用多说了\nnew CopyWebpackPlugin([\n    &#123;\n      // 我们现在可以输出svg格式的favicon了\n      from: 'images/favicon-32.svg'\n    &#125;\n])\n\n移除对 FTP 的支持\nGoogle Chrome 当前 FTP 的实现不支持加密连接（FTPS），也没有代理。 FTP 在浏览器中的使用率非常低，以致无法再投资于改进现有的 FTP 客户端。此外，所有受影响的平台上都提供了功能更强大的 FTP 客户端。 Google Chrome 72+删除了对通过 FTP 提取文档子资源和呈现顶级 FTP 资源的支持。当前，导航到 FTP URL 会导致显示目录列表或下载，具体取决于资源的类型。 Google Chrome 74+中的一个错误导致放弃了对通过 HTTP 代理访问 FTP URL 的支持。对 FTP 的代理支持已在 Google Chrome 76 中完全删除。 Google Chrome 的 FTP 实施的其余功能仅限于显示目录列表或通过未加密的连接下载资源。我们想弃用并删除此剩余功能，而不是维护不安全的 FTP 实现。\n总的来说：chrome 80+ 以后，google chrome 团队更 focus 的点就是安全相关的问题\nWeb workers 中支持 ES modulesModule Workers 是一种适用于 Web Worker 的新模式-得益于 JavaScript 模块化的优势。 Worker 构造函数现在可以接受一个{type：“ module”}选项，该选项更改了脚本的加载和执行方式，用于匹配\n&lt;script type=\"module\">\n    const worker = new Worker('worker.js', &#123;\n        type: 'module'\n    &#125;);\n&lt;/script>\n\n详见 Threading the web with module workers\nChrome 86 策略更新Chrome 86 在 2020 年 10 月推出了稳定版，现已全面应用于 Android、Chrome OS、Linux、macOS 和 Windows 等平台\n文件系统访问通过调用 showOpenFilePicker 方法，你可以唤起文件选择窗口，进而通过返回的文件句柄对文件进行读写。\nasync function getFileHandle() &#123;\n  const opts = &#123;\n    types: [\n      &#123;\n        description: 'Text Files',\n        accept: &#123;\n          'text/plain': ['.txt', '.text'],\n          'text/html': ['.html', '.htm']\n        &#125;\n      &#125;\n    ]\n  &#125;;\n  return await window.showOpenFilePicker(opts);\n&#125;\n\n全面阻止所有非 HTTPS 混合内容下载HTTPS 混合内容错误是指初始网页通过安全的 HTTPS 链接加载，但页面中其他资源，比如图像，视频，样式表，脚本却通过不安全的 HTTP 链接加载，这样就会出现混合内容错误，也就是不安全因素。\n攻击者可拦截不安全的下载地址，将程序替换成恶意软件、甚至访问更多的敏感信息。为管控这些风险，谷歌最终还是决定在 Chrome 中禁止加载不安全资源。\n从 M86 开始，图片类型的请求，会自动升级到 HTTPS，并且没有 HTTP 的降级，Audio&#x2F;Video 类型的请求早在 M80 就开始进行了自动升级\nreplaceChildren目前，要想替换某 DOM 节点下的全部子节点，必须要先通过 innerHTML 或 removeChild 删除全部子节点，然后再逐个添加，比较麻烦。为此，Chrome 支持了 replaceChildren 方法，可以用参数中的子节点列表替换原有的全部子节点，代码如下：\nparentNode.replaceChildren(newChildren);\n\n更醒目的 HTTP 安全警告在我们访问 HTTPS 网页时，地址栏最左侧会显示一个锁定图标来表明当前网站是安全的，但如果 HTTPS 网页中嵌入的是并不安全的 HTTP 表单，浏览器则不会给出任何提示信息。而实际上已经有钓鱼网站通过这种方式来盗取用户的敏感信息了。\n所以在 Chrome 86 中，如果 HTTPS 的网页中嵌入了不安全的 HTTP 表单，表单字段下方会有极为醒目的「此表单不安全」文本提示。\n\n后台标签页更省电如果一个标签页在后台运行了五分钟以上，这个页面就会被暂时冻结，相应的 CPU 使用也会被限制在 1% 左右；如果页面支持自动刷新，唤醒时间被限制在每一分钟一次。\n参考Chrome 80 版本到底升级了些什么两个你必须要重视的 Chrome 80 策略更新！！！2020 年 10 月 Chrome 86 重要更新解读Threading the web with module workers\n","slug":"chrome80","date":"2022-02-13T14:20:14.000Z","categories_index":"","tags_index":"","author_index":"Matrix"},{"id":"78e195a173181f2e8327460e98bdacbc","title":"CORS vs HSTS","content":"浏览器同源策略所谓同源就是浏览器的一个安全机制,不同源的客户端脚本没有在明确授权的情况下,不能读写对方资源。由于存在同源策略的限制,而又有需要跨域的业务,所以就有了 CORS 的出现。\n当资源位于不同协议、子域或端口的站点时，这个请求就是跨域的\n\nCORS 与 HSTSHSTS 全称：HTTP Strict Transport Security，意译：HTTP 严格传输安全，是一个 Web 安全策略机制。\n\n\n\n\n\n\n\n\n\nHSTS 解决什么问题？它解决的是：网站从 Http 转跳到 Https 时，可能出现的安全问题。Client 从 Http 切换到 Https 前是明文传输，因此是可以被 Man-In-The-Middle 劫持的，如下流程：\n\nHSTS 如何解决?要解决从 Http 切换到 Https 被劫持的问题，只要一开始就没有 Http 请求即可，流程如下：\n\nHSTS 如何知道哪些请求该转为 HTTPS，哪些不该转?\nHSTS HEADER(Strict-Transport-Security)\n最近一次请求的 HTTPS 响应中（RESPONSE）中，带上 HSTS HEADER：\nStrict-Transport-Security: &lt;max-age=>[; includeSubDomains][; preload]\n\nHSTS PRELOAD LIST\nHSTS HEADER(Strict-Transport-Security) 还是有个漏洞：\n\n如果第一次访问网站 A 就被劫持了，哪方案 1 岂不白搭？\n清 Cookies 或者 HSTS Header 过期了，下次访问岂不又风险重重？基于以上问题，就需要方案 2（HSTS Preload List）：\n\n官方说明：\nThis is a list of sites that are hardcoded into Chrome as being HTTPS only.\nHSTS Preload List 是一个站点列表，它被 hardcode 写入 Chrome 中，列表中的站点将会默认使用 HTTPS 进行访问。\n\nMost major browsers (Chrome, Firefox, Opera, Safari, IE 11 and Edge) also have HSTS preload lists based on the Chrome list. (See the HSTS compatibility matrix.)\n主流浏览器（Firefox, Opera, Safari, IE 11 and Edge）都有和 Chrome 一样的 HSTS Preload List。\nHSTS 可能导致 CORS 产生跨域问题HSTS (HTTP Strict Transport Security) 为了避免 HTTP 跳转到 HTTPS 时遭受潜在的中间人攻击，由浏览器本身控制到 HTTPS 的跳转。如同 CORS 一样，它也是有一个服务器的响应头 Strict-Transport-Security: max-age=5184000 来控制，此时浏览器访问该域名时，会使用 307 Internal Redirect，无需服务器干涉，自动跳转到 HTTPS 请求。\n「如果前端访问 HTTP 跨域请求，此时浏览器通过 HSTS 跳转到 HTTPS，但浏览器不会给出相应的 CORS 响应头部，就会发生跨域问题。」\nGET / HTTP/1.1\nHost: shanyue.tech\nOrigin: http://shanyue.tech\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36\nAccess to XMLHttpRequest at 'xxx' from origin 'xxx' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.\n\nCORSCORS 即跨域资源共享 (Cross-Origin Resource Sharing, CORS)。简而言之，就是在服务器端的响应中加入几个标头，使得浏览器能够跨域访问资源。\n这个响应头的字段设置就是：Access-Control-Allow-Origin: *\n浏览器将 CORS 请求分成两类：简单请求和非简单请求\n\n\n\n\n\n\n\n\n\n简单请求Method: 请求的方法是 GET、POST 及 HEADHeader: 请求头是 Content-Type (有限制)、Accept-Language、Content-Language 等Content-Type: 请求类型是 application&#x2F;x-www-form-urlencoded、multipart&#x2F;form-data 或 text&#x2F;plain\n非简单请求除简单请求外，均为非简单请求。一般需要开发者主动构造，在项目中常见的 Content-Type: application&#x2F;json 及 Authorization:  为典型的「非简单请求」\n预检请求(preflight request)非简单请求的 CORS 请求是会在正式通信之前进行一次预检请求，”预检”使用的请求方法是 OPTIONS , 表示这个请求是用来询问的\n// 跨域请求\nvar url = 'http://localhost:2333/cors';\nvar xhr = new XMLHttpRequest();\nxhr.open('PUT', url, true);\nxhr.setRequestHeader('X-Custom-Header', 'value');\nxhr.send();\n\n由于上面的代码使用的是 PUT 方法,并且发送了一个自定义头信息.所以是一个非简单请求,当浏览器发现这是一个非简单请求的时候,会自动发出预检请求,看看服务器可不可以接收这种请求,下面是”预检”的 HTTP 头信息\n// 跨域请求 预检 request headers\nOPTIONS /cors HTTP/1.1\nOrigin: localhost:2333\nAccess-Control-Request-Method: PUT // 表示使用的什么HTTP请求方法\nAccess-Control-Request-Headers: X-Custom-Header // 表示浏览器发送的自定义字段\nHost: localhost:2332\nAccept-Language: zh-CN,zh;q=0.9\nConnection: keep-alive\nUser-Agent: Mozilla/5.0...\n\n预检请求后的回应，服务器收到”预检”请求以后，检查了 Origin、Access-Control-Request-Method 和 Access-Control-Request-Headers 字段以后，确认允许跨源请求，就可以做出回应。\n// 跨域请求 预检 response headers\nHTTP/1.1 200 OK\nDate: Mon, 01 Dec 2008 01:15:39 GMT\nServer: Apache/2.0.61 (Unix)\nAccess-Control-Allow-Origin: http://localhost:2332 // 表示http://localhost:2332可以访问数据\nAccess-Control-Allow-Methods: GET, POST, PUT\nAccess-Control-Allow-Headers: X-Custom-Header\nContent-Type: text/html; charset=utf-8\nContent-Encoding: gzip\nContent-Length: 0\nKeep-Alive: timeout=2, max=100\nConnection: Keep-Alive\nContent-Type: text/plain\n\nCORS Response HeadersAccess-Control-Allow-Origin: 可以把资源共享给那些域名，支持 * 及 特定域名Access-Control-Allow-Credentials: 请求是否可以带 cookieAccess-Control-Allow-Methods: 请求所允许的方法, 「用于预检请求中」Access-Control-Allow-Headers: 请求所允许的头，「用于预检请求中」Access-Control-Expose-Headers: 那些头可以在响应中列出Access-Control-Max-Age: 预检请求的缓存时间\nKoa CORS 中间件原理\n必须校验是否有 Origin 请求头，跨域请求一定会有 Origin 请求头，@koa/cors 中间件源码 origin = options.origin || requestOrigin 可知，优先取 options.origin，默认以当前请求的 Origin 请求头作为 Access-Control-Allow-Origin 的响应头信息，保证当前请求允许跨域。\nmodule.exports = function(options) &#123;\n const defaults = &#123;\n   allowMethods: 'GET,HEAD,PUT,POST,DELETE,PATCH',\n &#125;;\n\n options = &#123;\n   ...defaults,\n   ...options,\n &#125;;\n\n // ...\n\n return async function cors(ctx, next) &#123;\n   // If the Origin header is not present terminate this set of steps.\n   // The request is outside the scope of this specification.\n   const requestOrigin = ctx.get('Origin');\n\n   // Always set Vary header\n   // https://github.com/rs/cors/issues/10\n   ctx.vary('Origin');\n\n   if (!requestOrigin) return await next();\n\n   let origin;\n   if (typeof options.origin === 'function') &#123;\n     origin = options.origin(ctx);\n     if (origin instanceof Promise) origin = await origin;\n     if (!origin) return await next();\n   &#125; else &#123;\n     origin = options.origin || requestOrigin;\n   &#125;\n\n   let credentials;\n   if (typeof options.credentials === 'function') &#123;\n     credentials = options.credentials(ctx);\n     if (credentials instanceof Promise) credentials = await credentials;\n   &#125; else &#123;\n     credentials = !!options.credentials;\n   &#125;\n\n   const headersSet = &#123;&#125;;\n\n   function set(key, value) &#123;\n     ctx.set(key, value);\n     headersSet[key] = value;\n   &#125;\n\n   if (ctx.method !== 'OPTIONS') &#123;\n     // Simple Cross-Origin Request, Actual Request, and Redirects\n     set('Access-Control-Allow-Origin', origin);\n\n     if (credentials === true) &#123;\n       set('Access-Control-Allow-Credentials', 'true');\n     &#125;\n\n     if (options.exposeHeaders) &#123;\n       set('Access-Control-Expose-Headers', options.exposeHeaders);\n    &#125;\n\n     if (!options.keepHeadersOnError) &#123;\n       return await next();\n     &#125;\n     try &#123;\n       return await next();\n     &#125; catch (err) &#123;\n       const errHeadersSet = err.headers || &#123;&#125;;\n       const varyWithOrigin = vary.append(errHeadersSet.vary || errHeadersSet.Vary || '', 'Origin');\n       delete errHeadersSet.Vary;\n\n       err.headers = &#123;\n         ...errHeadersSet,\n         ...headersSet,\n         ...&#123; vary: varyWithOrigin &#125;,\n       &#125;;\n       throw err;\n     &#125;\n   &#125; else &#123;\n     // Preflight Request\n\n     // If there is no Access-Control-Request-Method header or if parsing failed,\n     // do not set any additional headers and terminate this set of steps.\n     // The request is outside the scope of this specification.\n     if (!ctx.get('Access-Control-Request-Method')) &#123;\n       // this not preflight request, ignore it\n       return await next();\n     &#125;\n\n     ctx.set('Access-Control-Allow-Origin', origin);\n\n     if (credentials === true) &#123;\n       ctx.set('Access-Control-Allow-Credentials', 'true');\n     &#125;\n\n     if (options.maxAge) &#123;\n       ctx.set('Access-Control-Max-Age', options.maxAge);\n     &#125;\n\n     if (options.allowMethods) &#123;\n       ctx.set('Access-Control-Allow-Methods', options.allowMethods);\n     &#125;\n\n     let allowHeaders = options.allowHeaders;\n     if (!allowHeaders) &#123;\n       allowHeaders = ctx.get('Access-Control-Request-Headers');\n     &#125;\n     if (allowHeaders) &#123;\n       ctx.set('Access-Control-Allow-Headers', allowHeaders);\n     &#125;\n\n     ctx.status = 204;\n   &#125;\n &#125;;\n&#125;;\n\nCORS 与 Vary: Origin当请求网络静态资源为跨域资源（常见的为 cdn 静态资源，如 js、css、images 等）时，通常是会设置相关协商缓存响应头（Last-Modified、Etag）。这种一旦相同的资源链接需要根据不同的请求头（如User-Agent）响应不同的静态资源（PC、Mobile）时，可能会导致缓存资源响应错乱，此时必须设置 Vary: Origin, User-Agent，即代表为不同的 Origin 或 User-Agent 缓存不同的资源。\n详见 浏览器缓存及内容协商\n参考浏览器中的跨域问题与 CORS面试官问我 CORS 跨域，我直接一套操作斩杀！浅析 HSTS简单易懂 HSTS，你需要它！【安全】HSTS - 强制客户端（如浏览器）使用 HTTPS 与服务器创建连接\n","slug":"cors","date":"2022-02-12T16:54:51.000Z","categories_index":"","tags_index":"HTTP","author_index":"Matrix"},{"id":"0f1e554315f0274ca298957330a8910f","title":"浏览器缓存及内容协商","content":"浏览器的缓存机制浏览器的缓存机制也就是我们说的 HTTP 缓存机制，其机制是根据 HTTP 报文的缓存标识进行的。\n\n\n\n\n\n\n\n\n\n浏览器缓存过程： 强缓存、协商缓存。浏览器缓存位置一般分为四类： Service Worker、Memory Cache、Disk Cache、Push Cache\n强缓存强缓存是当我们访问 URL 的时候，不会向服务器发送请求，直接从缓存中读取资源，但是会返回 200 的状态码。\n如何设置强缓存？我们第一次进入页面，请求服务器，然后服务器进行应答，浏览器会根据 response Header 来判断是否对资源进行缓存，如果响应头中 expires、pragma 或者 cache-control 字段，代表这是强缓存，浏览器就会把资源缓存在 memory cache 或 disk cache 中。\n第二次请求时，浏览器判断请求参数，如果符合强缓存条件就直接返回状态码 200，从本地缓存中拿数据。否则把响应参数存在 request header 请求头中，看是否符合协商缓存，符合则返回状态码 304，不符合则服务器会返回全新资源。\n\n\n\n\n\n\n\n\n\n\nExpires是 HTTP1.0 控制网页缓存的字段，值为一个时间戳，准确来讲是格林尼治时间，服务器返回该请求结果缓存的到期时间，意思是，再次发送请求时，如果未超过过期时间，直接使用该缓存，如果过期了则重新请求。缺点：就是它判断是否过期是用本地时间来判断的，本地时间是可以自己修改的。\nCache-Control是 HTTP1.1 中控制网页缓存的字段，当 Cache-Control 都存在时，Cache-Control 优先级更高\n\npublic：资源客户端和服务器都可以缓存。\nprivate：资源只有客户端可以缓存。\nno-cache：客户端缓存资源，但是是否缓存需要经过协商缓存来验证。\nno-store：不使用缓存。\nmax-age：最大过期时间（距离当前请求的时间差）\n\n\nCache-Control 使用了 max-age 相对时间，解决了 expires 的问题\nPragma这个是 HTTP1.0 中禁用网页缓存的字段，其取值为 no-cache，和 Cache-Control 的 no-cache 效果一样\nVary(内容协商)要了解 Vary 的作用，先得了解 HTTP 的内容协商机制。有时候，同一个 URL 可以提供多份不同的文档，这就要求服务端和客户端之间有一个选择最合适版本的机制，这就是内容协商.服务端根据客户端发送的请求头中某些字段自动发送最合适的版本。可以用于这个机制的请求头字段又分两种：内容协商专用字段（Accept 字段）、其他字段.\n\n\n\n请求头字段\n说明\n响应头字段\n\n\n\nAccept\n告知服务器发送何种媒体类型\nContent-Type\n\n\nAccept-Language\n告知服务器发送何种语言\nContent-Language\n\n\nAccept-Charset\n告知服务器发送何种字符集\nContent-Type\n\n\nAccept-Encoding\n告知服务器采用何种压缩方式\nContent-Encoding\n\n\n// 例如客户端发送以下请求头\n// 表示它可以接受任何 MIME 类型的资源；支持采用 gzip、deflate 或 sdch 压缩过的资源；可以接受 zh-CN、en-US 和 en 三种语言，并且 zh-CN 的权重最高（q 取值 0 - 1，最高为 1，最低为 0，默认为 1），服务端应该优先返回语言等于 zh-CN 的版本。\nAccept:*/*\nAccept-Encoding:gzip,deflate,sdch\nAccept-Language:zh-CN,en-US;q=0.8,en;q=0.6\n\n// 浏览器的响应头可能是这样的\n// 表示这个文档确切的 MIME 类型是 text/javascript；文档内容进行了 gzip 压缩；响应头没有 Content-Language 字段，通常说明返回版本的语言正好是请求头 Accept-Language 中权重最高的那个\nContent-Type: text/javascript\nContent-Encoding: gzip\n\n上面四个 Accept 字段并不够用，例如要针对特定浏览器如 IE6 输出不一样的内容，就需要用到请求头中的 User-Agent 字段。类似的，请求头中的 Cookie 也可能被服务端用做输出差异化内容的依据。由于客户端和服务端之间可能存在一个或多个中间实体（如缓存服务器），而缓存服务最基本的要求是给用户返回正确的文档。如果服务端根据不同 User-Agent 返回不同内容，而缓存服务器把 IE6 用户的响应缓存下来，并返回给使用其他浏览器的用户，肯定会出问题所以 HTTP 协议规定，如果服务端提供的内容取决于 User-Agent 这样「常规 Accept 协商字段之外」的请求头字段，那么响应头中必须包含 Vary 字段，且 Vary 的内容必须包含 User-Agent。同理，如果服务端同时使用请求头中 User-Agent 和 Cookie 这两个字段来生成内容，那么响应中的 Vary 字段看上去应该是这样的：\nVary: User-Agent, Cookie\n\n也就是说 Vary 字段用于列出一个响应字段列表，告诉缓存服务器遇到同一个 URL 对应着不同版本文档的情况时，如何缓存和筛选合适的版本。\n\n\n缓存位置强缓存会把资源房放到 memory cache 和 disk cache 中，那什么资源放在 memory cache，什么资源放在 disk cache 中？\n\n查找浏览器缓存时会按顺序查找: Service Worker -&gt; Memory Cache -&gt; Disk Cache -&gt; Push Cache。\n\n\n\n\n\n\n\n\n\nService Worker是运行在浏览器背后的独立线程，一般可以用来实现缓存功能。使用 Service Worker 的话，传输协议必须为 HTTPS。因为 Service Worker 中涉及到请求拦截，所以必须使用 HTTPS 协议来保障安全。Service Worker 的缓存与浏览器其他内建的缓存机制不同，它可以让我们自由控制缓存哪些文件、如何匹配缓存、如何读取缓存，并且缓存是持续性的。\nMemory Cache内存中的缓存，主要包含的是当前中页面中已经抓取到的资源，例如页面上已经下载的样式、脚本、图片等。读取内存中的数据肯定比磁盘快，内存缓存虽然读取高效，可是缓存持续性很短，会随着进程的释放而释放。一旦我们关闭 Tab 页面，内存中的缓存也就被释放了。\nDisk Cache存储在硬盘中的缓存，读取速度慢点，但是什么都能存储到磁盘中，比之 Memory Cache 胜在容量和存储时效性上。在所有浏览器缓存中，Disk Cache 覆盖面基本是最大的。它会根据 HTTP Herder 中的字段判断哪些资源需要缓存，哪些资源可以不请求直接使用，哪些资源已经过期需要重新请求。并且即使在跨站点的情况下，相同地址的资源一旦被硬盘缓存下来，就不会再次去请求数据。绝大部分的缓存都来自 Disk Cache。memory cache 要比 disk cache 快的多。举个例子：从远程 web 服务器直接提取访问文件可能需要 500 毫秒(半秒)，那么磁盘访问可能需要 10-20 毫秒，而内存访问只需要 100 纳秒，更高级的还有 L1 缓存访问(最快和最小的 CPU 缓存)只需要 0.5 纳秒。很神奇的，我们又看到了一个 prefetch cache，这个又是什么呢?\n\nprefetch cache(预取缓存)link 标签上带了 prefetch，再次加载会出现。prefetch 是预加载的一种方式，被标记为 prefetch 的资源，将会被浏览器在空闲时间加载。 4. Push Cache\nPush Cache(推送缓存)是 HTTP&#x2F;2 中的内容，当以上三种缓存都没有命中时，它才会被使用。它只在会话（Session）中存在，一旦会话结束就被释放，并且缓存时间也很短暂，在 Chrome 浏览器中只有 5 分钟左右，同时它也并非严格执行 HTTP 头中的缓存指令。\n\n协商缓存协商缓存就是强缓存失效后，浏览器携带缓存标识向服务器发送请求，由服务器根据缓存标识来决定是否使用缓存的过程。\n协商缓存生效，返回 304\n协商缓存失效，返回 200 和请求结果\n\n\n\n\n\n\n\n\n\nLast-Modified &#x2F; If-Modified-SinceLast-Modified 是服务器响应请求时，返回该资源文件在服务器最后被修改的时间。If-Modified-Since 则是客户端再次发起该请求时，携带上次请求返回的 Last-Modified 值，通过此字段值告诉服务器该资源上次请求返回的最后被修改时间。服务器收到该请求，发现请求头含有 If-Modified-Since 字段，则会根据 If-Modified-Since 的字段值与该资源在服务器的最后被修改时间做对比，若服务器的资源最后被修改时间大于 If-Modified-Since 的字段值，则重新返回资源，状态码为 200；否则则返回 304，代表资源无更新，可继续使用缓存文件。\nEtag &#x2F; If-None-MatchEtag 是服务器响应请求时，返回当前资源文件的一个唯一标识(由服务器生成)。If-None-Match 是客户端再次发起该请求时，携带上次请求返回的唯一标识 Etag 值，通过此字段值告诉服务器该资源上次请求返回的唯一标识值。服务器收到该请求后，发现该请求头中含有 If-None-Match，则会根据 If-None-Match 的字段值与该资源在服务器的 Etag 值做对比，一致则返回 304，代表资源无更新，继续使用缓存文件；不一致则重新返回资源文件，状态码为 200。\nCORS 与 Vary: Origin在讨论 CORS 与 Vary 关系时，先抛出一个问题：\n\n\n\n\n\n\n\n\n\n如何避免 CDN 为 PC 端缓存移动端页面？\n假设有两个域名访问 static.shanyue.tech 的跨域资源\n\nfoo.shanyue.tech，响应头中返回 Access-Control-Allow-Origin: foo.shanyue.tech\nbar.shanyue.tech，响应头中返回 Access-Control-Allow-Origin: bar.shanyue.tech\n\n看起来一切正常，但平静的水面下波涛暗涌:\n「如果 static.shanyue.tech 资源被 CDN 缓存，bar.shanyue.tech 再次访问资源时，因缓存问题，因此此时返回的是 Access-Control-Allow-Origin: foo.shanyue.tech，此时会有跨域问题」\n此时，Vary: Origin 就上场了，代表为不同的 Origin 缓存不同的资源，这在各个服务器端 CORS 中间件也能体现出来。\nKoa 关于 CORS 的处理函数\nreturn async function cors(ctx, next) &#123;\n  // If the Origin header is not present terminate this set of steps.\n  // The request is outside the scope of this specification.\n  const requestOrigin = ctx.get('Origin');\n\n  // Always set Vary header\n  // https://github.com/rs/cors/issues/10\n  ctx.vary('Origin');\n&#125;\n\n\n\n\n\n\n\n\n\n\n服务器端通过响应头 Origin 来判断是否为跨域请求，并以此设置多域名跨域，但要加上 Vary: Origin。\n参考彻底理解浏览器的缓存机制前端浏览器缓存知识梳理(1.6w 字)浏览器灵魂之问，请问你能接得住几个？HTTP 协议中 Vary 的一些研究浏览器中的跨域问题与 CORS\n","slug":"broswer-cache","date":"2022-02-12T13:40:50.000Z","categories_index":"","tags_index":"HTTP","author_index":"Matrix"},{"id":"230f463a6828a545fa6d14af02ab1fd6","title":"Monorepo","content":"什么是 Monorepo?Monorepo 其实不是一个新的概念，在软件工程领域，它已经有着十多年的历史了。概念上很好理解，就是把多个项目放在一个仓库里面，相对立的是传统的 MultiRepo 模式，即每个项目对应一个单独的仓库来分散管理。\nMonorepo 是一种将多个项目代码存储在一个仓库里的软件开发策略（”mono” 来源于希腊语 μόνος 意味单个的，而 “repo”，显而易见地，是 repository 的缩写）。\n\n现代的前端工程已经越来越离不开 Monorepo 了，无论是业务代码还是工具库，越来越多的项目已经采用 Monorepo 的方式来进行开发。Google 宁愿把所有的代码都放在一个 Monorepo 工程下面，Vue 3、Yarn、Npm7 等等知名开源项目的源码也是采用 Monorepo 的方式来进行管理的。\n一般 Monorepo 的目录如下所示，在 packages 存放多个子项目，并且每个子项目都有自己的 package.json:\n├── packages\n|   ├── pkg1\n|   |   ├── package.json\n|   ├── pkg2\n|   |   ├── package.json\n├── package.json\n\n\n那 Monorepo 究竟有什么魔力，让大家如此推崇，落地如此之广呢？\nMonorepo 最佳实践之 Yarn WorkspacesYarn Workspaces（工作空间&#x2F;工作区，本文使用工作空间这一名称）是 Yarn 提供的 Monorepo 依赖管理机制，从 Yarn 1.0 开始默认支持，用于在代码仓库的根目录下管理多个 project 的依赖。\nYarn Workspaces 的目标是令使用 Monorepo 变得简单，以一种更具声明性的方式处理 yarn link 的主要使用场景。简而言之，它们允许多个项目共存在同一个代码库中，并相互交叉引用，并且保证一个项目源代码的任何修改都会立即应用到其他项目中。\n重复安装、管理繁琐的缺点从 npm package 诞生起便一直存在，node_modules hell 就是该问题的集中体现。\n\n为了简化流程，很多大型项目采用了 Monorepo 的做法，即把所有的包放在一个仓库中管理\n\n\n\n\n\n\n\n\n\nBabel、React、Vue、Jest 等都使用了 monorepo 的管理方式。\nMenorepo 的优点是可以在一个仓库里维护多个 package，可统一构建，跨 package 调试、依赖管理、版本发布都十分方便，搭配工具还能统一生成 CHANGELOG；代价是即使只开发其中一个 package 也需要安装整个项目的依赖。以 jest 为例，其 Monorepo 代码结构为：\n| jest/\n| ---- package.json\n| ---- packages/\n| -------- babel-jest/\n| ------------ package.json\n| -------- babel-plugin-jest-hoist/\n| ------------ package.json\n| -------- babel-preset-jest/\n| ------------ package.json\n| -------- .../\n\n\n为何使用 Yarn Workspaces在以 Monorepo 为代码组织方式的项目中，依赖管理的规模和复杂度均有不小的提升（这也不难理解，随着”数量“的增加，任何小的问题都会变得复杂）。如何减少依赖重复安装？如何优雅实现跨目录代码共享？如何对依赖版本进行统一管理以避免版本冲突？所以这些问题都可以借助 Yarn Workspaces 来解决！Yarn 官方对于 Yarn Workspaces 的使用时机（Why would you want to do this?）是这样描述的：\n\n\n\n\n\n\n\n\n\nYour dependencies can be linked together, which means that your workspaces can depend on one another while always using the most up-to-date code available. This is also a better mechanism than yarn link since it only affects your workspace tree rather than your whole system.\n工作区内的依赖关系可以链接在一起，这意味着工作区可以相互依赖，同时始终使用最新的可用代码。这也是一个相对于 yarn link 更好的机制，因为它只影响你的工作空间树，而不是整个系统。\nAll your project dependencies will be installed together, giving Yarn more latitude to better optimize them.\n所有的项目依赖关系都将被安装在一起，为 Yarn 提供更多的自由度来更好地优化它们。\nYarn will use a single lockfile rather than a different one for each project, which means fewer conflicts and easier reviews.\n对于每个项目，Yarn 将使用一个公共的的锁文件而不是为每个工程使用一个不同的锁文件，这意味着更少的冲突和更容易的版本审查。\n如何启用 Workspace\n\n\n\n\n\n\n\n\n\n确保项目中安装有 yarn\n在项目根目录的 packag.json 中增加如下配置:\n\n&#123;\n  \"private\": true,\n  \"workspaces\": [\"packages/*\"]\n&#125;\nmonorepo 方案实践锁定环境：VoltaVolta 是一个 JavaScript 工具管理器，它可以让我们轻松地在项目中锁定 node，npm 和 yarn 的版本。你只需在安装完 Volta 后，在项目的根目录中执行 volta pin 命令，那么无论您当前使用的 node 或 npm（yarn）版本是什么，volta 都会自动切换为您指定的版本。\n相较于 nvm，Volta 还具有一个诱人的特性：当您项目的 CLI 工具与全局 CLI 工具不一致时，Volta 可以做到在项目根目录下自动识别，切换到项目指定的版本\n复用 packages：workspace使用 monorepo 策略后，收益最大的两点是：\n避免重复安装包，因此减少了磁盘空间的占用，并降低了构建时间；内部代码可以彼此相互引用；这两项好处全部都可以由一个成熟的包管理工具来完成，对前端开发而言，即是 yarn（1.0 以上）或 npm（7.0 以上）通过名为 workspaces 的特性实现的（⚠️ 注意，支持 workspaces 特性的 npm 目前依旧不是 LTS 版本）。\n为了实现前面提到的两点收益，您需要在代码中做三件事：\n\n调整目录结构，将相互关联的项目放置在同一个目录，推荐命名为 packages；\n在项目根目录里的 package.json 文件中，设置 workspaces 属性，属性值为之前创建的目录；\n同样，在 package.json 文件中，设置 private 属性为 true（为了避免我们误操作将仓库发布）；\n\n经过修改，您的项目目录看起来应该是这样：\n.\n├── package.json\n└── packages/\n    ├── @mono/project_1/ # 推荐使用 `@&lt;项目名>/&lt;子项目名>` 的方式命名\n    │   ├── index.js\n    │   └── package.json\n    └── @mono/project_2/\n        ├── index.js\n        └── package.json\n\n\n而当您在项目根目录中执行 npm install 或 yarn install 后，您会发现在项目根目录中出现了 node_modules 目录，并且该目录不仅拥有所有子项目共用的 npm 包，还包含了我们的子项目。因此，我们可以在子项目中通过各种模块引入机制，像引入一般的 npm 模块一样引入其他子项目的代码。请注意我们对子项目的命名，统一以 @&#x2F; 开头，这是一种社区最佳实践，不仅可以让用户更容易了解整个应用的架构，也方便您在项目中更快捷的找到所需的子项目。至此，我们已经完成了 monorepo 策略的核心部分，实在是很容易不是吗？但是老话说「行百里者半九十」，距离优雅的搭建一个 monorepo 项目，我们还有一些路要走。\n统一配置：合并同类项 - Eslint，Typescript 与 BabelTypeScript我们可以在 packages 目录中放置 tsconfig.settting.json 文件，并在文件中定义通用的 ts 配置，然后，在每个子项目中，我们可以通过 extends 属性，引入通用配置，并设置 compilerOptions.composite 的值为 true，理想情况下，子项目中的 tsconfig 文件应该仅包含下述内容：\n&#123;\n  \"extends\": \"../tsconfig.setting.json\", // 继承 packages 目录下通用配置\n  \"compilerOptions\": &#123;\n    \"composite\": true, // 用于帮助 TypeScript 快速确定引用工程的输出文件位置\n    \"outDir\": \"dist\",\n    \"rootDir\": \"src\"\n  &#125;,\n  \"include\": [\"src\"]\n&#125;\n\n\nEslint对于 Eslint 配置文件，我们也可以如法炮制，这样定义子项目的 .eslintrc 文件内容：\n&#123;\n  \"extends\": \"../../.eslintrc\", // 注意这里的不同\n  \"parserOptions\": &#123;\n    \"project\": \"tsconfig.json\"\n  &#125;\n&#125;\n\nBabelBabel 配置文件合并的方式与 TypeScript 如出一辙，甚至更加简单，我们只需在子项目中的 .babelrc 文件中这样声明即可：\n&#123;\n  \"extends\": \"../.babelrc\"\n&#125;\n\n当一切准备就绪后，我们的项目目录应该大致呈如下所示的结构：\n.\n├── package.json\n├── .eslintrc\n└── packages/\n    │   ├── tsconfig.settings.json\n    │   ├── .babelrc\n    ├── @mono/project_1/\n    │   ├── index.js\n    │   ├── .eslintrc\n    │   ├── .babelrc\n    │   ├── tsconfig.json\n    │   └── package.json\n    └───@mono/project_2/\n        ├── index.js\n        ├── .eslintrc\n        ├── .babelrc\n        ├── tsconfig.json\n        └── package.json\n\n\n统一命令脚本：scripty如果您的子项目足够多，您可能会发现，每个 package.json 文件中的 scripts 属性都大同小异，并且一些 scripts 充斥着各种 Linux 语法，例如管道操作符，重定向或目录生成。重复带来低效，复杂则使人难以理解，这都是需要我们解决的问题。\n这里给出的解决方案是，使用 scripty 管理您的脚本命令，简单来说，scripty 允许您将脚本命令定义在文件中，并在 package.json 文件中直接通过文件名来引用。这使我们可以实现如下目的：\n子项目间复用脚本命令；像写代码一样编写脚本命令，无论它有多复杂，而在调用时，像调用函数一样调用；\n通过使用 scripty 管理我们的 monorepo 应用，目录结构看起来将会是这样：\n.\n├── package.json\n├── .eslintrc\n├── scirpts/ # 这里存放所有的脚本\n│   │   ├── packages/ # 包级别脚本\n│   │   │   ├── build.sh\n│   │   │   └── test.sh\n│   └───└── workspaces/ # 全局脚本\n│           ├── build.sh\n│           └── test.sh\n└── packages/\n    │   ├── tsconfig.settings.json\n    │   ├── .babelrc\n    ├── @mono/project_1/\n    │   ├── index.js\n    │   ├── .eslintrc\n    │   ├── .babelrc\n    │   ├── tsconfig.json\n    │   └── package.json\n    └── @mono/project_2/\n        ├── index.js\n        ├── .eslintrc\n        ├── .babelrc\n        ├── tsconfig.json\n        └── package.json\n\n注意，我们脚本分为两类「package 级别」与「workspace 级别」，并且分别放在两个文件夹内。这样做的好处在于，我们既可以在项目根目录执行全局脚本，也可以针对单个项目执行特定的脚本。\n通过使用 scripty，子项目的 package.json 文件中的 scripts 属性将变得非常精简：\n&#123;\n  ...\n  \"scripts\": &#123;\n    \"test\": \"scripty\",\n    \"lint\": \"scripty\",\n    \"build\": \"scripty\"\n  &#125;,\n  \"scripty\": &#123;\n    \"path\": \"../../scripts/packages\" // 注意这里我们指定了 scripty 的路径\n  &#125;,\n  ...\n&#125;\n\n统一包管理：Lerna\n\n\n\n\n\n\n\n\n\n当多个子项目放在一个代码仓库，并且子项目之间又相互依赖时，我们面临的棘手问题有两个：\n\n如果我们需要在多个子目录执行相同的命令，我们需要手动进入各个目录，并执行命令；\n\n当一个子项目更新后，我们只能手动追踪依赖该项目的其他子项目，并升级其版本。\n\n\n通过使用 Lerna，这些棘手的问题都将不复存在。当在项目根目录使用 npx lerna init 初始化后，我们的根目录会新增一个 lerna.json 文件，默认内容为：\n&#123;\n  \"packages\": [\"packages/*\"],\n  \"version\": \"0.0.0\"\n&#125;\n\n让我们稍稍改动这个文件，使其变为：\n&#123;\n  \"packages\": [\"packages/*\"],\n  \"npmClient\": \"yarn\",\n  \"version\": \"independent\",\n  \"useWorkspaces\": true,\n&#125;\n\n可以注意到，我们显示声明了我们的包客户端（npmClient）为 yarn，并且让 Lerna 追踪我们 workspaces 设置的目录，这样我们就依旧保留了之前 workspaces 的所有特性（子项目引用和通用包提升）。\n除此之外一个有趣的改动在于我们将 version 属性指定为一个关键字 independent，这将告诉 lerna 应该将每个子项目的版本号看作是相互独立的。当某个子项目代码更新后，运行 lerna publish 时，Lerna 将监听到代码变化的子项目并以交互式 CLI 方式让开发者决定需要升级的版本号，关联的子项目版本号不会自动升级，反之，当我们填入固定的版本号时，则任一子项目的代码变动，都会导致所有子项目的版本号基于当前指定的版本号升级。\nLerna 提供了很多 CLI 命令以满足我们的各种需求，但根据 2&#x2F;8 法则，您应该首先关注以下这些命令：\n\nlerna init：常见一个新的 lerna 仓库（repo）或将现有的仓库升级为适配当前 版本的 Lerna。参数 --independent/-i – 使用独立的版本控制模式\nlerna bootstrap：等同于 lerna link + yarn install，用于创建符合链接并安装依赖包；\nlerna run：会像执行一个 for 循环一样，在所有子项目中执行 npm script 脚本，并且，它会非常智能的识别依赖关系，并从根依赖开始执行命令；\nlerna exec：像 lerna run 一样，会按照依赖顺序执行命令，不同的是，它可以执行任何命令，例如 shell 脚本；\nlerna publish：发布代码有变动的 package，因此首先您需要在使用 Lerna 前使用 git commit 命令提交代码，好让 Lerna 有一个 baseline；\nlerna add：将本地或远程的包作为依赖添加至当前的 monorepo 仓库中，该命令让 Lerna 可以识别并追踪包之间的依赖关系，因此非常重要；\n\n参考All in one：项目级 monorepo 策略最佳实践Monorepo 最佳实践之 Yarn Workspaces现代前端工程为什么越来越离不开 Monorepo?lerna 多包管理实践\n","slug":"monorepo","date":"2022-02-09T23:18:46.000Z","categories_index":"","tags_index":"Monorepo","author_index":"Matrix"},{"id":"51e9acccf01c1d764ee3a75bbf79b49b","title":"HTTP2","content":"维基百科关于 HTTP&#x2F;2 的介绍，可以看下定义和发展历史:\nWiki\nRFC 7540 定义了 HTTP&#x2F;2 的协议规范和细节，本文的细节主要来自此文档，建议先看一遍本文，再回过头来照着协议大致过一遍 RFC，如果想深入某些细节再仔细翻看 RFC\nRFC7540\nWhy use it ?HTTP&#x2F;1.1 存在的问题:\n\nTCP 连接数限制对于同一个域名，浏览器最多只能同时创建 6 - 8 个 TCP 连接 (不同浏览器不一样)。为了解决数量限制，出现了 域名分片 技术，其实就是资源分域，将资源放在不同域名下 (比如二级子域名下)，这样就可以针对不同域名创建连接并请求，以一种讨巧的方式突破限制，但是滥用此技术也会造成很多问题，比如每个 TCP 连接本身需要经过 DNS 查询、三步握手、慢启动等，还占用额外的 CPU 和内存，对于服务器来说过多连接也容易造成网络拥挤、交通阻塞等，对于移动端来说问题更明显，可以参考这篇文章: Why Domain Sharding is Bad News for Mobile Performance and Users。在图中可以看到新建了六个 TCP 连接，每次新建连接 DNS 解析需要时间(几 ms 到几百 ms 不等)、TCP 慢启动也需要时间、TLS 握手又要时间，而且后续请求都要等待队列调度\n线头阻塞 (Head Of Line Blocking) 问题每个 TCP 连接同时只能处理一个请求 - 响应，浏览器按 FIFO 原则处理请求，如果上一个响应没返回，后续请求 - 响应都会受阻。为了解决此问题，出现了 管线化 - pipelining 技术，但是管线化存在诸多问题，比如第一个响应慢还是会阻塞后续响应、服务器为了按序返回相应需要缓存多个响应占用更多资源、浏览器中途断连重试服务器可能得重新处理多个请求、还有必须客户端 - 代理 - 服务器都支持管线化\nHeader 内容多，而且每次请求 Header 不会变化太多，没有相应的压缩传输优化方案\n为了尽可能减少请求数，需要做合并文件、雪碧图、资源内联等优化工作，但是这无疑造成了单个请求内容变大延迟变高的问题，且内嵌的资源不能有效地使用缓存机制\n明文传输不安全\n\nHTTP2 的优势二进制分帧层 (Binary Framing Layer)帧是数据传输的最小单位，以二进制传输代替原本的明文传输，原本的报文消息被划分为更小的数据帧:\n\nh1 和 h2 的报文对比:\n\n图中 h2 的报文是重组解析过后的，可以发现一些头字段发生了变化，而且所有头字段均小写\n多路复用 (MultiPlexing)在一个 TCP 连接上，我们可以向对方不断发送帧，每帧的 stream identifier 的标明这一帧属于哪个流，然后在对方接收时，根据 stream identifier 拼接每个流的所有帧组成一整块数据。把 HTTP&#x2F;1.1 每个请求都当作一个流，那么多个请求变成多个流，请求响应数据分成多个帧，不同流中的帧交错地发送给对方，这就是 HTTP&#x2F;2 中的多路复用。\n流的概念实现了单连接上多请求 - 响应并行，解决了线头阻塞的问题，减少了 TCP 连接数量和 TCP 连接慢启动造成的问题\n所以 http2 对于同一域名只需要创建一个连接，而不是像 http&#x2F;1.1 那样创建 6~8 个连接:\n\n服务端推送 (Server Push)浏览器发送一个请求，服务器主动向浏览器推送与这个请求相关的资源，这样浏览器就不用发起后续请求。Server-Push 主要是针对资源内联做出的优化，相较于 http&#x2F;1.1 资源内联的优势:\n\n客户端可以缓存推送的资源\n客户端可以拒收推送过来的资源\n推送资源可以由不同页面共享\n服务器可以按照优先级推送资源\n\nHeader 压缩 (HPACK)使用 HPACK 算法来压缩首部内容上图来自 Ilya Grigorik 的 PPT - HTTP&#x2F;2 is here, let’s optimize!\n可以清楚地看到 HTTP2 头部使用的也是键值对形式的值，而且 HTTP1 当中的请求行以及状态行也被分割成键值对，还有所有键都是小写，不同于 HTTP1。除此之外，还有一个包含静态索引表和动态索引表的索引空间，实际传输时会把头部键值表压缩，使用的算法即 HPACK，其原理就是匹配当前连接存在的索引空间，若某个键值已存在，则用相应的索引代替首部条目，比如 “:method: GET” 可以匹配到静态索引中的 index 2，传输时只需要传输一个包含 2 的字节即可；若索引空间中不存在，则用字符编码传输，字符编码可以选择哈夫曼编码，然后分情况判断是否需要存入动态索引表中\n\n静态索引静态索引表是固定的，对于客户端服务端都一样，目前协议商定的静态索引包含 61 个键值，详见 Static Table Definition - RFC 7541，比如前几个如下\n\n\n索引\n字段值\n键值\n\n\n\nindex\nHeader Name\nHeader Value\n\n\n1\n:authority\n单元格\n\n\n2\n:method\nGET\n\n\n3\n:method\nPOST\n\n\n4\n:path\n&#x2F;\n\n\n5\n:path\n&#x2F;index.html\n\n\n6\n:scheme\nhttp\n\n\n7\n:scheme\nhttps\n\n\n8\n:status\n200\n\n\n\n动态索引动态索引表是一个 FIFO 队列维护的有空间限制的表，里面含有非静态表的索引。动态索引表是需要连接双方维护的，其内容基于连接上下文，一个 HTTP2 连接有且仅有一份动态表。当一个首部匹配不到索引时，可以选择把它插入动态索引表中，下次同名的值就可能会在表中查到索引并替换。但是并非所有首部键值都会存入动态索引，因为动态索引表是有空间限制的，最大值由 SETTING 帧中的 SETTINGS_HEADER_TABLE_SIZE (默认 4096 字节) 设置\n\n应用层的重置连接对于 HTTP&#x2F;1 来说，是通过设置 tcp segment 里的 reset flag 来通知对端关闭连接的。这种方式会直接断开连接，下次再发请求就必须重新建立连接。HTTP&#x2F;2 引入 RST_STREAM 类型的 frame，可以在不断开连接的前提下取消某个 request 的 stream，表现更好。\n请求优先级设置HTTP&#x2F;2 里的每个 stream 都可以设置依赖 (Dependency) 和权重，可以按依赖树分配优先级，解决了关键请求被阻塞的问题\nHTTP&#x2F;1 的几种优化可以弃用合并文件、内联资源、雪碧图、域名分片对于 HTTP&#x2F;2 来说是不必要的，使用 h2 尽可能将资源细粒化，文件分解地尽可能散，不用担心请求数多\n参考HTTP2 详解HTTP1.0、HTTP1.1 和 HTTP2.0 的区别\n","slug":"http2","date":"2022-02-08T22:19:20.000Z","categories_index":"","tags_index":"Network","author_index":"Matrix"},{"id":"acb839066d366821abd556a15e4a7b04","title":"CDN","content":"什么是 CDN？CDN 的全称是 Content Delivery Network，即内容分发网络。是指一种通过互联网互相连接的电脑网络系统，利用最靠近每位用户的服务器，更快、更可靠地将音乐、图片、视频、应用程序及其他文件发送给用户，来提供高性能、可扩展性及低成本的网络内容传递给用户。\n现实中我们都用过天猫超市，在上面买东西非常方便。天猫超市的模式是货品先入天猫超市（后文简称为”猫超”）的菜鸟仓，然后由猫超统一派送的。\n\nCDN 的基本工作过程一图秒懂 CDN 原理（以访问网站某网页资源请求为例）\n引入 CDN 之前\n用户在自己的浏览器中输入要访问的网站域名\n浏览器向本地 DNS 服务器请求对该域名的解析\n本地 DNS 服务器中如果缓存有这个域名的解析结果，则直接响应用户的解析请求\n本地 DNS 服务器中如果没有关于这个域名的解析结果的缓存，则以迭代方式向整个 DNS 系统请求解析，获得应答后将结果反馈给浏览器\n浏览器得到域名解析结果，就是该域名相应的服务设备的 IP 地址\n浏览器获取 IP 地址之后，经过标准的 TCP 握手流程，建立 TCP 连接\n浏览器向服务器发起 HTTP 请求\n服务器将用户请求内容传送给浏览器\n经过标准的 TCP 挥手流程，断开 TCP 连接\n\n引入 CDN 之后\n当用户点击网站页面上的内容 URL，先经过本地 DNS 系统解析，如果本地 DNS 服务器没有相应域名的缓存，则本地 DNS 系统会将域名的解析权交给 CNAME 指向的 CDN 专用 DNS 服务器\nCDN 的 DNS 服务器将 CDN 的全局负载均衡设备 IP 地址返回给用户\n用户向 CDN 的全局负载均衡设备发起 URL 访问请求\nCDN 全局负载均衡设备根据用户 IP 地址，以及用户请求的 URL，选择一台用户所属区域的区域负载均衡设备，并将请求转发到此设备上\n基于以下这些条件的综合分析之后，区域负载均衡设备会选择一个最优的缓存服务器节点，并从缓存服务器节点处得到缓存服务器的 IP 地址，最终将得到的 IP 地址返回给全局负载均衡设备\n根据用户 IP 地址，判断哪一个边缘节点距用户最近\n根据用户所请求的 URL 中携带的内容名称，判断哪一个边缘节点上有用户所需内容\n查询各个边缘节点当前的负载情况，判断哪一个边缘节点尚有服务能力\n\n\n全局负载均衡设备把服务器的 IP 地址返回给用户\n用户向缓存服务器发起请求，缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，而区域均衡设备依然将它分配给了用户，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地\n\nCNAME 记录是什么？他存在的意义是什么？记录就是把一个域名解析到一个 IP 地址（Address，特制数字 IP 地址），而 CNAME 记录就是把域名解析到另外一个域名。其功能是差不多，CNAME 将几个主机名指向一个别名，其实跟指向 IP 地址是一样的，因为这个别名也要做一个 A 记录的。但是使用 CNAME 记录可以很方便地变更 IP 地址。如果一台服务器有 100 个网站，他们都做了别名，该台服务器变更 IP 时，只需要变更别名的 A 记录就可以了。\n如果服务商给你一个 ip，假如哪天服务商想把 ip 地址换一个，很多人域名上对应的 ip 地址就要跟着变化，要让所有人都一起改完，完全没有办法做到的事情，换成 cname 就没事了，你用你的 cdn，他改他的 ip 地址。唯一的坏处就是，第一次 DNS 解析域名的时候会多解析一次。总结来看，好处远大于坏处。\n什么是 CNAME 记录？CName 记录是 Canonical Name 的简称，通常称别名指向，CNAME 记录可用于将一个域名别名为另一个规范名称的域名系统（DNS）资源记录。　　网站是由一组由一组唯一标识的位置（称为 IP 地址）提供服务的；但是要访问这些站点（例如：晓得博客），我们通常会键入它们对应的域名，这些域名更容易记住。要找到正确的 IP 地址，您的浏览器将联系域名服务器（DNS），并在其数据库中查询 IP 地址。\nCNAME 记录如何使用？例如，假设您有几个子域，例如http://www.mydomain.com，http://ftp.mydomain.com，http://mail.mydomain.com等，并且您希望这些子域指向您的主域名http://mydomain.com。您可以创建CNAME记录，而不是为每个子域创建A记录并将其绑定到您域的IP地址。如下表所示，如果服务器的 IP 地址发生更改，则只需更新一个 A 记录，并且所有子域都会自动更新，因为所有 CNAMES 都指向带有 A 记录的主域：http://mydomain.com指向服务器IP地址，并通过http://www.mydomain.com指向相同的地址http://mydomain.com。如果IP地址发生更改，则只需要在一个地方进行更新即可：只需为修改A记录http://mydomain.com，那么http://www.mydomain.com自动继承更改。　　 CNAME 记录必须始终指向另一个域名，永远不要直接指向 IP 地址。如果您尝试将 CNAME 记录指向 IP 地址，DNSimple 的记录编辑器会警告您。CNAME 对其他记录必须是唯一的。CNAME 记录局限性　　 CNAME 记录必须始终指向另一个域名，并且永远不要直接指向 IP 地址。　　您不能为主域名（http://mydomain.com）本身创建CNAME记录，该记录必须是A记录。　　例如，您不能将http://mydomain.com映射到http://google.com，但是可以将http://google.mydomain.com映射到http://google.com。　　使用 CNAME 记录意味着有一个额外的请求发送到 DNS 服务器，这可能会导致几毫秒的延迟。　　一个 CNAME 记录不能与另一个具有相同名称的记录共存。不能同时有 CNAME 和 TXT 记录http://www.example.com。　　一个 CNAME 可以指向另一个 CNAME，尽管出于性能原因通常不建议使用此配置。如果适用，CNAME 应该尽可能地指向目标名称，以避免不必要的性能开销。\n如何解决 CDN 缓存\n资源 url 参数加时间戳url 的参数加上时间戳，每次更新时时间戳也跟随更新，重新使 cdn 边缘节点同步源服务器最新数据。调用 cdn 服务商提供的刷新缓存接口\n\nhttp://www.cdn.com/static/images/test.png # 没加时间戳\nhttp://www.cdn.com/static/images/test.png?_t=202012290910 # 加了时间戳\n\n\n调用 cdn 服务商提供的刷新缓存接口CDN 边缘节点对开发者是透明的，相比于浏览器 Ctrl+F5 的强制刷新来使浏览器本地缓存失效，开发者可以通过 CDN 服务商提供的“刷新缓存”接口来达到清理 CDN 边缘节点缓存的目的。这样开发者在更新数据后，可以使用“刷新缓存”功能来强制 CDN 节点上的数据缓存过期，保证客户端在访问时，拉取到最新的数据。\n\nCDN 的应用场景\n网站站点&#x2F;应用加速站点或者应用中大量静态资源的加速分发，建议将站点内容进行动静分离，动态文件可以结合云服务器 ECS，静态资源如各类型图片、html、css、js 文件等，建议结合 对象存储 OSS 存储海量静态资源，可以有效加速内容加载速度，轻松搞定网站图片、短视频等内容分发\n视音频点播&#x2F;大文件下载分发加速支持各类文件的下载、分发，支持在线点播加速业务，如 mp4、flv 视频文件或者平均单个文件大小在 20M 以上，主要的业务场景是视音频点播、大文件下载（如安装包下载）等，建议搭配对象存储 OSS 使用，可提升回源速度，节约近 2&#x2F;3 回源带宽成本。\n视频直播加速（内测中）视频流媒体直播服务，支持媒资存储、切片转码、访问鉴权、内容分发加速一体化解决方案。结合弹性伸缩服务，及时调整服务器带宽，应对突发访问流量；结合媒体转码服务，享受高速稳定的并行转码，且任务规模无缝扩展。目前 CDN 直播加速已服务内部用户测试并优化，即将上线\n移动应用加速移动 APP 更新文件（apk 文件）分发，移动 APP 内图片、页面、短视频、UGC 等内容的优化加速分发。提供 httpDNS 服务，避免 DNS 劫持并获得实时精确的 DNS 解析结果，有效缩短用户访问时间，提升用户体验。\n\n参考也许是史上最全的一次 CDN 详解一图秒懂 CDN 原理\n","slug":"cdn","date":"2022-02-08T19:56:46.000Z","categories_index":"","tags_index":"Network","author_index":"Matrix"}]